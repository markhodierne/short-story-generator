{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6l1b44e2ZdLMvNPy/YMxu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["The goal of this project is to build a small language model which generates very short stories.\n","\n","I will build a decoder-only Transformer model from scratch -- and train it on data from the Tiny Stories dataset, which is a collection of very short stories used for training small language models.\n","\n","Transformer-based models like GPT-3 have demonstrated impressive capabilities in generating coherent and contextually relevant text, making them useful for applications like creative writing, conversational agents, and content generation."],"metadata":{"id":"X7ZndmBnZOJY"}},{"cell_type":"code","source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h_HMEVcgvN3C","executionInfo":{"status":"ok","timestamp":1712566385015,"user_tz":-60,"elapsed":34229,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"ac35f4d6-bb6f-49df-8a46-74cf984d2b67"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import os\n","import math\n","import random\n","\n","import pandas as pd\n","import numpy as np\n","import sentencepiece as spm\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.optim import Adam\n","from torch.utils.data import DataLoader, Dataset\n","from torch.nn.utils.rnn import pad_sequence\n","\n","from nltk.translate.bleu_score import corpus_bleu\n","from tqdm import tqdm\n"],"metadata":{"id":"R6OwkyELqvOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Paths\n","os.chdir('/content/gdrive/My Drive/Colab Notebooks/Transformers and Tiny Stories/')\n","\n","tiny_stories_train = 'TinyStoriesV2-GPT4-train.txt'\n","tiny_stories_val = \"TinyStoriesV2-GPT4-valid.txt\"\n","tiny_stories_100 = \"tiny_stories_100.txt\"\n","tiny_stories_1000 = \"tiny_stories_1000.txt\"\n","tiny_stories_10000 = \"tiny_stories_10000.txt\"\n","\n","train_set_path = \"train_set.txt\"\n","val_set_path = \"val_set.txt\"\n","\n","spm_model = 'spm.model'"],"metadata":{"id":"SkFHh0FMwkB6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pre-processing\n","\n","Truncate the stories because longer ones tend to be nonsensicle."],"metadata":{"id":"ZSAgkS2BaXk6"}},{"cell_type":"code","source":["# Preprocess the tiny stories dataset\n","\n","story_limit = 100\n","\n","# Read the input text file\n","with open('test_stories.txt', 'r') as file:\n","    lines = file.readlines()\n","\n","# Initialize variables to store reformatted stories\n","reformatted_stories = []\n","\n","# Iterate through the lines\n","story = ''\n","num_stories = 0\n","for line in lines:\n","    if line.strip() == '<|endoftext|>':\n","        # End of story symbol found, add the current story to the list and reset story variable\n","        reformatted_stories.append(story)\n","        story = ''\n","        num_stories += 1\n","        if num_stories == story_limit:\n","            break\n","    else:\n","        # Concatenate lines of the current story\n","        story += line.strip() + ' '\n","\n","# Truncate stories to 1500 characters\n","reformatted_stories = [story[:1500] for story in reformatted_stories]\n","\n","# Write the reformatted stories to a new text file\n","with open('reformatted_tiny_stories_train.txt', 'w') as file:\n","    for story in reformatted_stories:\n","        file.write(story + '\\n')\n"],"metadata":{"id":"RjHAg6mOu0a3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Open the larger text file for reading\n","with open('reformatted_tiny_stories_train.txt', 'r') as larger_file:\n","    # Read the first 10000 rows\n","    tiny_10 = [next(larger_file) for _ in range(10)]\n","\n","# Shuffle the lines randomly\n","random.shuffle(tiny_10)\n","\n","# Calculate the number of lines for the training set and validation set\n","total_lines = len(tiny_10)\n","train_size = int(0.8 * total_lines)\n","val_size = total_lines - train_size\n","\n","print(\"Train set:\", train_size)\n","print(\"Val set:\", val_size)\n","\n","# Split the lines into training set and validation set\n","train_set = tiny_10[:train_size]\n","val_set = tiny_10[train_size:]\n","\n","print(\"Actual Train set:\", len(train_set))\n","print(\"Actual Val set:\", len(val_set))\n","\n","# Write the training set to a file\n","with open(train_set_path, 'w') as train_file:\n","    for line in train_set:\n","        train_file.write(line)\n","\n","## Write the training set to a file\n","with open(val_set_path, 'w') as val_file:\n","    for line in val_set:\n","        val_file.write(line)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRySsl4vxUj_","executionInfo":{"status":"ok","timestamp":1712436989922,"user_tz":-60,"elapsed":306,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"e6855158-ebb6-40a3-dbbf-0d8a6c14c016"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train set: 8\n","Val set: 2\n","Actual Train set: 8\n","Actual Val set: 2\n"]}]},{"cell_type":"code","source":["vocab_size = 4500\n","model_prefix = 'spm'\n","\n","# Train SentencePiece model\n","spm.SentencePieceTrainer.train(f'--pad_id=0 --bos_id=1 --eos_id=2 --unk_id=3 --input={tiny_stories_10000} --model_prefix={model_prefix} --vocab_size={vocab_size}')\n"],"metadata":{"id":"UgGhy92yvnnX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load pre-trained tokenizer\n","sp = spm.SentencePieceProcessor()\n","sp.load(spm_model)\n","\n","# Get the actual vocabulary size\n","vocab_size = sp.get_piece_size()\n","print(sp.id_to_piece(2))\n","\n","# Print the actual vocabulary size\n","print(\"Actual vocabulary size:\", vocab_size)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcBS7hyUv1-B","executionInfo":{"status":"ok","timestamp":1712521956155,"user_tz":-60,"elapsed":286,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"bd2793f3-5f31-4503-e1f9-7c69d058428a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["</s>\n","Actual vocabulary size: 4500\n"]}]},{"cell_type":"code","source":["class Tokenizer:\n","    def __init__(self):\n","\n","        # Initialize an empty set to store unique words\n","        unique_words = set()\n","\n","        # Read the text file line by line and tokenize each line into words\n","        with open('reformatted_tiny_stories_train.txt', 'r', encoding='utf-8') as file:\n","            for line in file:\n","                words = line.split()\n","                unique_words.update(words)\n","\n","        vocab = ['<pad>', '<s>', '</s>'] + sorted(set(unique_words))\n","\n","        self.stoi = {c: i for i, c in enumerate(vocab)}\n","        self.itos = {i: c for i, c in enumerate(vocab)}\n","        self.vocab_size = len(vocab)\n","\n","    def encode(self, story):\n","        return [self.stoi[w] for w in story.split()]\n","\n","    def decode(self, tokens):\n","        return ' '.join([self.itos[t] for t in tokens])\n","\n","\n","tokenizer = Tokenizer()\n","vocab_size = tokenizer.vocab_size\n","print(\"Vocabulary size:\", vocab_size)\n","print(tokenizer.itos)\n","\n","# Example\n","story_encoded = tokenizer.encode('cat sat')\n","story_decoded = tokenizer.decode([599, 1870])\n","print(story_encoded)\n","print(story_decoded)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mo9D_bbM94qN","executionInfo":{"status":"ok","timestamp":1712566393148,"user_tz":-60,"elapsed":1593,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"6855d3a0-3dba-4dda-b894-ca2ed815bc94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 2485\n","{0: '<pad>', 1: '<s>', 2: '</s>', 3: '\"', 4: '\"Actually,', 5: '\"Ahoy,', 6: '\"Are', 7: '\"Bad', 8: '\"Be', 9: '\"Bob', 10: '\"But', 11: '\"Can', 12: '\"Daddy,', 13: '\"Do', 14: '\"Don\\'t', 15: '\"Freeze!\"', 16: '\"Frog', 17: '\"Go', 18: '\"Good', 19: '\"Goodbye,', 20: '\"He', 21: '\"Hello!', 22: '\"Hello,', 23: '\"Help', 24: '\"Help,', 25: '\"Hey,', 26: '\"Hi', 27: '\"Hi!', 28: '\"Hi,', 29: '\"How', 30: '\"I', 31: '\"I\\'m', 32: '\"It', 33: '\"It\\'s', 34: '\"Jen', 35: '\"John!', 36: '\"Let\\'s', 37: '\"Lily,', 38: '\"Look', 39: '\"Look,', 40: '\"Mama,', 41: '\"Max', 42: '\"Maybe', 43: '\"Mom', 44: '\"Mom,', 45: '\"My', 46: '\"No!', 47: '\"No,', 48: '\"OK,', 49: '\"Of', 50: '\"Oh', 51: '\"Oh,', 52: '\"Okay,', 53: '\"Okay,\"', 54: '\"Ollie,', 55: '\"One,', 56: '\"Please', 57: '\"Rex', 58: '\"Sam,', 59: '\"She', 60: '\"Sorry\".', 61: '\"Spirits', 62: '\"Stop', 63: '\"Sue,', 64: '\"Sure,', 65: '\"Teddy,', 66: '\"Thank', 67: '\"That', 68: '\"That\\'s', 69: '\"The', 70: '\"This', 71: '\"Tim,', 72: '\"Tom,', 73: '\"Tweet,', 74: '\"We', 75: '\"What', 76: '\"What\\'s', 77: '\"When', 78: '\"Who', 79: '\"Why', 80: '\"Woof!', 81: '\"Wow,', 82: '\"Yes,', 83: '\"You', 84: '\"You\\'re', 85: '\"Yuck,', 86: '\"bang', 87: '\"freeze\"', 88: '\"freeze.\"', 89: '\"hi\"', 90: '\"look', 91: '\"snap,\"', 92: \"'freeze,'\", 93: '-', 94: 'A', 95: 'After', 96: 'All', 97: 'Amy', 98: 'Amy.', 99: 'And', 100: 'Anna', 101: 'As', 102: 'At', 103: 'Be', 104: 'Beaver', 105: 'Beaver,', 106: 'Before', 107: 'Ben', 108: 'Ben!', 109: \"Ben's\", 110: 'Ben,', 111: 'Ben.', 112: 'Bird!\"', 113: 'Bob', 114: 'Bob,', 115: 'Bob.', 116: 'But', 117: 'But,', 118: 'Can', 119: 'Chew', 120: 'Chew.', 121: 'Dad', 122: \"Dad's\", 123: 'Dad.', 124: 'Did', 125: 'Do', 126: \"Don't\", 127: 'During', 128: 'Ella', 129: 'Every', 130: 'Everyone', 131: 'Fighting', 132: 'Finally,', 133: 'Fluffy', 134: 'Fluffy.', 135: 'Follow', 136: 'From', 137: 'Get', 138: 'Give', 139: 'Goodbye,', 140: 'Have', 141: 'He', 142: 'Her', 143: 'His', 144: 'How', 145: 'I', 146: \"I'm\", 147: 'In', 148: 'Inside', 149: 'Instead,', 150: \"Isn't\", 151: 'It', 152: \"It's\", 153: 'It’s', 154: 'Jack', 155: 'Jack.', 156: 'Jane', 157: 'Jane.', 158: 'Jen', 159: 'Jen.', 160: 'Jim', 161: 'Jim.', 162: 'John', 163: 'John!', 164: \"John's\", 165: 'John,', 166: 'John.', 167: 'John:', 168: 'Just', 169: 'Kate', 170: 'Kate.', 171: 'Later,', 172: 'Leave', 173: 'Leo', 174: \"Leo's\", 175: 'Leo.', 176: \"Let's\", 177: 'Lila', 178: 'Lila.', 179: 'Lily', 180: 'Lily!', 181: \"Lily's\", 182: 'Lily,\"', 183: 'Lily.', 184: 'Lily.\"', 185: 'Little', 186: 'Look', 187: 'Lucy', 188: 'Lucy!\"', 189: \"Lucy's\", 190: 'Lucy,', 191: 'Lucy.', 192: 'Many', 193: 'Max', 194: 'Max!', 195: \"Max's\", 196: 'Max,', 197: 'Max.', 198: 'Mia', 199: 'Milly', 200: 'Milly.', 201: 'Molly', 202: 'Mom', 203: 'Mom!\"', 204: 'Moral:', 205: 'Mr.', 206: 'Mrs.', 207: 'My', 208: 'Next', 209: 'Now', 210: 'Now,', 211: 'Ollie', 212: 'Ollie!\"', 213: \"Ollie's\", 214: 'Ollie.', 215: 'Once', 216: 'Once,', 217: 'One', 218: 'Only', 219: 'Penny', 220: 'Penny.', 221: 'Penny’s', 222: 'Please,', 223: 'Pond\".', 224: 'Remy', 225: 'Remy!\"', 226: 'Remy.', 227: 'Rex', 228: 'Rex.', 229: 'Sam', 230: 'Sam!\"', 231: 'Sam,', 232: 'Sam.', 233: 'Sara', 234: 'Sara.', 235: 'Saturday,', 236: 'See', 237: 'See?\"', 238: 'She', 239: 'So', 240: 'So,', 241: 'Some', 242: 'Sometimes', 243: 'Soon', 244: 'Soon,', 245: 'Spot', 246: 'Spot.', 247: 'Stay', 248: 'Suddenly,', 249: 'Sue', 250: \"Sue's\", 251: 'Sue,', 252: 'Sue.', 253: 'Teddy', 254: 'Thank', 255: 'That', 256: \"That's\", 257: 'The', 258: 'Their', 259: 'Then', 260: 'Then,', 261: 'There', 262: 'There,', 263: 'They', 264: 'This', 265: 'Thomas', 266: 'Thomas.', 267: 'Tim', 268: 'Tim!', 269: \"Tim's\", 270: 'Tim,', 271: 'Tim,\"', 272: 'Tim.', 273: 'Today,', 274: 'Tom', 275: 'Tom!', 276: \"Tom's\", 277: 'Tom,', 278: 'Tom,\"', 279: 'Tom.', 280: 'Tommy', 281: 'Tommy,', 282: 'True', 283: 'True,', 284: 'True.\"', 285: 'We', 286: \"We'll\", 287: 'What', 288: 'When', 289: 'Where', 290: 'While', 291: 'Whiskers', 292: 'Whiskers,', 293: 'Why', 294: 'Will', 295: 'With', 296: 'Woof!\"', 297: 'You', 298: 'Zoom', 299: 'Zoom.', 300: 'a', 301: 'ab', 302: 'able', 303: 'about', 304: 'accidentally', 305: 'ache.\"', 306: 'across', 307: 'act', 308: 'acting', 309: 'admire', 310: 'admired', 311: 'adventure', 312: 'adventure!', 313: 'adventure.', 314: 'adventures', 315: 'adventures.', 316: 'afraid.', 317: 'after', 318: 'after.', 319: 'afternoon', 320: 'again', 321: 'again!', 322: 'again!\"', 323: 'again.', 324: 'agree.', 325: 'agreed', 326: 'agreed.', 327: 'ahead,', 328: 'air', 329: 'air!', 330: 'air.', 331: 'air.”', 332: 'all', 333: 'all!', 334: 'all.', 335: 'allows', 336: 'almost', 337: 'alone!\"', 338: 'already', 339: 'also', 340: 'always', 341: 'am', 342: 'amazed', 343: 'amazed!', 344: 'amazing', 345: 'an', 346: 'and', 347: 'angels', 348: 'angry', 349: 'angry.', 350: 'animals', 351: 'animals,', 352: 'animals.', 353: 'animals?\"', 354: 'another', 355: 'any', 356: 'anymore.', 357: 'anything', 358: 'anything.', 359: 'anyway!', 360: 'anywhere.', 361: 'applaud.', 362: 'appreciation.', 363: 'are', 364: 'are.', 365: 'area', 366: 'arms.', 367: 'around', 368: 'around.', 369: 'arranged', 370: 'arrived,', 371: 'art.', 372: 'artwork', 373: 'as', 374: 'ask', 375: 'asked', 376: 'asked,', 377: 'asked.', 378: 'asking', 379: 'asking.', 380: 'asking?\"', 381: 'asks.', 382: 'at', 383: 'ate', 384: 'attach', 385: 'attached', 386: 'attention.', 387: 'away', 388: 'away!', 389: 'away!\"', 390: 'away,', 391: 'away.', 392: 'awe', 393: 'baby', 394: 'back', 395: 'back!\"', 396: 'back,', 397: 'back.', 398: 'backed', 399: 'backs.', 400: 'backyard', 401: 'backyard.', 402: 'bad', 403: 'bad!\"', 404: 'bad.', 405: 'bad.\"', 406: 'badly,', 407: 'bag', 408: 'bait.', 409: 'balance', 410: 'balance.', 411: 'balancing', 412: 'bald.', 413: 'ball', 414: 'ball,', 415: 'ball.', 416: 'banana', 417: 'bang\"', 418: 'barely', 419: 'bark', 420: 'barked', 421: 'barked,', 422: 'barking.', 423: 'basket.', 424: 'bath', 425: 'bath.', 426: 'battery', 427: 'be', 428: 'beach', 429: 'beach.', 430: 'beamed', 431: 'bear', 432: 'bear!', 433: \"bear's\", 434: 'bear,', 435: 'bear.', 436: 'beautiful', 437: 'beautiful.', 438: 'became', 439: 'because', 440: 'become', 441: 'becoming', 442: 'bed', 443: 'been', 444: 'before', 445: 'before.', 446: 'began', 447: 'began,', 448: 'behind', 449: 'being', 450: 'believe', 451: 'bell', 452: 'bell,', 453: 'bell.', 454: 'belongs', 455: 'best', 456: 'best.', 457: 'better', 458: 'better.', 459: 'big', 460: 'big,', 461: 'big.', 462: 'bigger', 463: 'bigger.', 464: 'bird', 465: 'bird!', 466: 'bird!\"', 467: 'bird,', 468: 'bird.', 469: 'bird.\"', 470: 'bird?\"', 471: 'birdcage', 472: 'birdcage.', 473: 'birds', 474: 'birds,', 475: 'birds.', 476: 'bit', 477: 'bites', 478: 'black', 479: 'blew', 480: 'block', 481: 'blue', 482: 'blue,', 483: 'boat,', 484: 'boat.', 485: 'boats.', 486: 'bobbed.', 487: 'body', 488: 'bone.', 489: 'book', 490: 'books.', 491: 'bored.', 492: 'both', 493: 'bottom', 494: 'bottom,', 495: 'bought', 496: 'bowl', 497: 'bowl!\"', 498: 'bowl,\"', 499: 'bowl.', 500: 'bowl.\"', 501: 'box', 502: 'box.', 503: 'boxes', 504: 'boxes,\"', 505: 'boxes.', 506: 'boy', 507: \"boy's\", 508: 'boy,', 509: 'boy.', 510: 'boy.\"', 511: 'boys', 512: 'boys,\"', 513: 'branch', 514: 'brave', 515: 'brave,', 516: 'brave.', 517: 'bravely', 518: 'bravery.', 519: 'break', 520: 'breaks', 521: 'breath', 522: 'breathe', 523: 'breathing', 524: 'bright', 525: 'bright.', 526: 'brightly', 527: 'bringing', 528: 'broke', 529: 'broken', 530: 'broken!', 531: 'broken,\"', 532: 'broken.', 533: 'brother', 534: 'brother.', 535: 'brothers', 536: 'brought', 537: 'brown', 538: 'brown,', 539: 'brushes.', 540: 'bucket', 541: 'bucket.', 542: 'bug', 543: 'bug!\"', 544: 'bug,', 545: 'bug.', 546: 'bug.\"', 547: 'bugs', 548: 'bugs.', 549: 'bugs.\"', 550: 'building', 551: 'bull', 552: 'bull,', 553: 'bull.', 554: 'bumpy.', 555: 'bunny', 556: \"bunny's\", 557: 'bunny.', 558: 'burn', 559: 'burning.', 560: 'bush,', 561: 'bush.', 562: 'bushes.', 563: 'but', 564: 'butterflies', 565: 'buy', 566: 'buy.', 567: 'by', 568: 'by.', 569: 'called', 570: 'calls', 571: 'calm.', 572: 'came', 573: 'camp,', 574: 'camp.', 575: 'can', 576: \"can't\", 577: 'can.', 578: 'cannot', 579: 'car', 580: 'car,', 581: 'car.', 582: 'car?\"', 583: 'card', 584: 'care', 585: 'care.', 586: 'careful', 587: 'careful,', 588: 'careful.', 589: 'careful.\"', 590: 'carefully', 591: 'caring', 592: 'carpet', 593: 'carpet.', 594: 'carried', 595: 'carrot', 596: 'carry', 597: 'carrying', 598: 'cars', 599: 'cat', 600: 'cat.', 601: 'catch', 602: 'catching', 603: 'caught', 604: 'cause.', 605: 'cave', 606: 'cave.', 607: 'celebrated', 608: 'chance.', 609: 'changed,', 610: 'charity', 611: 'chased', 612: 'cheered', 613: 'cheese', 614: 'cheese,', 615: 'cheese.', 616: 'cheese?\"', 617: 'chickens', 618: 'chickens.', 619: 'children.', 620: 'choose', 621: 'chubby', 622: 'church', 623: 'church.', 624: 'clap', 625: 'clapped', 626: 'claws.', 627: 'clean', 628: 'clean.', 629: 'cleaning', 630: 'cliff', 631: 'cliff.', 632: 'climb', 633: 'climbed', 634: 'close', 635: 'close.', 636: 'closed', 637: 'closely.', 638: 'closer', 639: 'closer.', 640: 'closet', 641: 'closet,\"', 642: 'clumsy', 643: 'coat,', 644: 'cold.', 645: 'cold.”', 646: 'collar', 647: 'color', 648: 'colored', 649: 'colorful', 650: 'colors', 651: 'colors!\"', 652: 'colors,\"', 653: 'colors.', 654: 'colors.\"', 655: 'colour', 656: 'come', 657: 'comes', 658: 'comfort', 659: 'coming', 660: 'complete', 661: 'complete.', 662: 'conquered', 663: 'continue', 664: 'continued', 665: 'cooked', 666: 'cool', 667: 'cool!\"', 668: 'cool.', 669: 'corner', 670: 'corner.', 671: 'costume', 672: 'costume.', 673: 'could', 674: 'could.', 675: \"couldn't\", 676: \"couldn't.\", 677: 'count', 678: 'count.', 679: 'counted', 680: 'counting', 681: 'course', 682: 'course!\"', 683: 'course,', 684: 'cow', 685: 'cows,', 686: 'crawl', 687: 'crawled', 688: 'crawling', 689: 'crayons', 690: 'create.', 691: 'creation!', 692: 'creations', 693: 'creative', 694: 'creative!”', 695: 'creative.', 696: 'creativity.', 697: 'cried', 698: 'cried.', 699: 'cry', 700: 'cry.', 701: 'crying', 702: 'crying.', 703: 'cube', 704: 'cube.', 705: 'cup', 706: 'curious', 707: 'curious.', 708: 'curiously', 709: 'customer.', 710: 'customer.\"', 711: 'cut', 712: 'cute', 713: 'cute!\"', 714: 'd', 715: 'dad', 716: 'dad.', 717: 'daddy', 718: 'dance', 719: 'dance.', 720: 'danced', 721: 'dancing', 722: 'dangerous.', 723: 'dare', 724: 'dared', 725: 'daughter', 726: 'day', 727: 'day,', 728: 'day.', 729: 'day.\"', 730: 'days,', 731: 'days.', 732: 'dead', 733: 'deaf', 734: 'deaf,', 735: 'decide', 736: 'decided', 737: 'decorate', 738: 'deep', 739: 'deep,', 740: 'deep.', 741: 'deliver', 742: 'dependable', 743: 'design', 744: 'design.', 745: 'designing', 746: 'did', 747: 'did,', 748: 'did.', 749: \"didn't\", 750: 'different', 751: 'different.', 752: 'difficult', 753: 'dig', 754: 'dinner!\"', 755: 'dinner,', 756: 'dinner.', 757: 'direction', 758: 'dirty,', 759: 'dirty.', 760: 'dirty.\"', 761: 'disagreed.', 762: 'discovered', 763: 'discovery.', 764: 'discussed', 765: 'disgusting.\"', 766: 'disgusting:', 767: 'display', 768: 'do', 769: 'do.', 770: 'do.”', 771: 'do?\"', 772: 'does', 773: 'dog', 774: 'dog!', 775: 'dog!\"', 776: 'dog,', 777: 'dog.', 778: 'doggy,', 779: 'dogs.', 780: 'dogs.\"', 781: 'doing?', 782: 'doing?\"', 783: 'doll', 784: 'doll.', 785: \"don't\", 786: 'done,', 787: 'don’t', 788: 'door', 789: 'door.', 790: 'door.\"', 791: 'down', 792: 'down,', 793: 'down.', 794: 'drain', 795: 'drain.', 796: 'drank', 797: 'dreamt', 798: 'dress', 799: 'dress,', 800: 'dress.', 801: 'dress.\"', 802: 'dresses.', 803: 'drew', 804: 'drink', 805: 'drinking', 806: 'drip.', 807: 'dropped', 808: 'dropped.', 809: 'dry,', 810: 'dry.', 811: 'duck!\"', 812: 'duck,', 813: 'duck.', 814: 'ducks', 815: 'dull', 816: 'dull.', 817: 'during', 818: 'each', 819: 'eager', 820: 'ear', 821: 'east', 822: 'east,', 823: 'east.', 824: 'east?\"', 825: 'easy', 826: 'easy!', 827: 'easy.', 828: 'eat', 829: 'eating', 830: 'eats', 831: 'edge', 832: 'edge.', 833: 'elderly', 834: 'end', 835: 'end!', 836: 'end,', 837: 'end.', 838: 'ends.', 839: 'energetic', 840: 'energy', 841: 'enjoy', 842: 'enjoyed', 843: 'enjoying', 844: 'entered', 845: 'even', 846: 'eventually', 847: 'ever', 848: 'every', 849: 'everyday.', 850: 'everyone', 851: 'everyone,', 852: 'everywhere', 853: 'everywhere.', 854: 'excited', 855: 'excited!', 856: 'excited,', 857: 'excited.', 858: 'excitedly', 859: 'excitement.', 860: 'exciting', 861: 'exercise.', 862: 'exercising', 863: 'exit.', 864: 'explain,', 865: 'explore', 866: 'explore,', 867: 'explored', 868: 'exploring', 869: 'exploring.', 870: 'eye', 871: 'eyes', 872: 'eyes.', 873: 'face.', 874: 'faces.', 875: 'fair.', 876: 'fairer.', 877: 'fall', 878: 'fallen', 879: 'falls', 880: 'fame', 881: 'family', 882: 'family.', 883: 'family.\"', 884: 'famous', 885: 'far.', 886: 'farm', 887: 'farm!', 888: 'farm.', 889: 'farmer', 890: \"farmer's\", 891: 'farmer.', 892: 'fast', 893: 'fast.', 894: 'faster,', 895: 'father', 896: 'favorite', 897: 'fear,', 898: 'fed', 899: 'feel', 900: 'feeling', 901: 'feels', 902: 'feet', 903: 'feet.', 904: 'fell', 905: 'fell,', 906: 'felt', 907: 'fence', 908: 'few', 909: 'field', 910: 'field,', 911: 'field.', 912: 'fierce', 913: 'fight.', 914: 'fighting,', 915: 'fighting.', 916: 'figure', 917: 'filled', 918: 'finally', 919: 'find', 920: 'finding', 921: 'fine', 922: 'fine.', 923: 'finished', 924: 'finished,', 925: 'fire', 926: 'fire.', 927: 'firemen', 928: 'firemen.', 929: 'first', 930: 'first!\"', 931: 'first,\"', 932: 'fish', 933: \"fish's\", 934: 'fish,', 935: 'fish.', 936: 'fisherman', 937: 'fisherman’s', 938: 'fit', 939: 'fix', 940: 'fixed', 941: 'fixed.', 942: 'flag', 943: 'flag,', 944: 'flame.', 945: 'flames', 946: 'flaps', 947: 'flew', 948: 'floated', 949: 'floor', 950: 'floor.', 951: 'flower', 952: 'flower,\"', 953: 'flower.', 954: 'flowers', 955: 'flowers.', 956: 'flowers.\"', 957: 'flowers?\"', 958: 'fly', 959: 'fly.', 960: 'fly.\"', 961: 'flying', 962: 'flying.', 963: 'folder', 964: 'folder.', 965: 'follow', 966: 'followed', 967: 'food', 968: 'food.', 969: 'foolish', 970: 'foolish.', 971: 'foot.', 972: 'football', 973: 'football.', 974: 'for', 975: 'forest', 976: 'forest,', 977: 'forest.', 978: 'forever.\"', 979: 'forget.', 980: 'forgive', 981: 'forgot', 982: 'forming', 983: 'forth.', 984: 'forward', 985: 'found', 986: 'free', 987: 'free.', 988: 'fresh', 989: 'fresh.\"', 990: 'friend', 991: 'friend,', 992: 'friend,\"', 993: 'friend.', 994: 'friend.\"', 995: 'friendly', 996: 'friends', 997: \"friends'\", 998: 'friends,', 999: 'friends.', 1000: 'friends.\"', 1001: 'friends:', 1002: 'frightened.', 1003: 'frog', 1004: \"frog's\", 1005: 'frog.', 1006: 'frogs', 1007: 'from', 1008: 'from.', 1009: 'fruit', 1010: 'fruit\".', 1011: 'fruit,', 1012: 'fruit.', 1013: 'full', 1014: 'fun', 1015: 'fun!', 1016: 'fun!\"', 1017: 'fun,', 1018: 'fun,\"', 1019: 'fun.', 1020: 'fur.', 1021: 'furry!\"', 1022: 'game', 1023: 'game.', 1024: 'games', 1025: 'garage.', 1026: 'garden', 1027: 'garden,', 1028: 'garden.', 1029: 'garden:', 1030: 'gate', 1031: 'gate.', 1032: 'gathered', 1033: 'gave', 1034: 'gaze', 1035: 'gentle', 1036: 'get', 1037: 'getting', 1038: 'giggle.', 1039: 'girl', 1040: 'girl,', 1041: 'girl.', 1042: 'give', 1043: 'gives', 1044: 'glad', 1045: 'glad.', 1046: 'glass', 1047: 'glass,', 1048: 'glue', 1049: 'go', 1050: 'go,\"', 1051: 'go.', 1052: 'going', 1053: 'gold!\"', 1054: 'gone!\"', 1055: 'gone.', 1056: 'gone.\"', 1057: 'good', 1058: 'good.', 1059: 'goodbye', 1060: 'goodbye.', 1061: 'got', 1062: 'grab', 1063: 'grabbed', 1064: 'grabs', 1065: 'grandma', 1066: 'grandma.', 1067: 'grandmother', 1068: 'grateful', 1069: 'grateful,', 1070: 'grateful.', 1071: 'great', 1072: 'green', 1073: 'grew', 1074: 'ground', 1075: 'ground.', 1076: 'grow.', 1077: 'growing.', 1078: 'grumpy', 1079: 'grumpy.', 1080: 'guard', 1081: 'guard.', 1082: 'guilty.', 1083: 'guitar', 1084: 'guitar.', 1085: 'gum', 1086: 'gum.', 1087: 'gum?\".', 1088: 'gun', 1089: 'gun.', 1090: 'had', 1091: 'hair', 1092: 'hair.', 1093: 'hairy', 1094: 'half,', 1095: 'half.', 1096: 'hammer', 1097: 'hammer,', 1098: 'hammer.', 1099: 'hand', 1100: 'hand.', 1101: 'hands', 1102: 'hands.', 1103: 'happened', 1104: 'happened.', 1105: 'happens', 1106: 'happily', 1107: 'happily.', 1108: 'happy', 1109: 'happy!', 1110: 'happy,', 1111: 'happy.', 1112: 'hard', 1113: 'hard.', 1114: 'hard.\"', 1115: 'has', 1116: 'hat', 1117: 'hat!\"', 1118: 'hat,', 1119: 'hat.', 1120: 'have', 1121: 'have.\"', 1122: 'having', 1123: 'hay', 1124: 'hay.', 1125: 'he', 1126: \"he's\", 1127: 'head', 1128: 'head.', 1129: 'headed', 1130: 'hear', 1131: 'hear,', 1132: 'hear?\"', 1133: 'heard', 1134: 'heart', 1135: 'heavy.', 1136: 'hedge.', 1137: 'held', 1138: 'help', 1139: 'help!\"', 1140: 'help,', 1141: 'help.', 1142: 'help?\"', 1143: 'helped', 1144: 'helpful', 1145: 'helping', 1146: 'helps', 1147: 'her', 1148: 'her,', 1149: 'her.', 1150: 'her?\"', 1151: 'here', 1152: 'here.', 1153: 'here?\"', 1154: 'hero!', 1155: 'hide-and-seek.', 1156: 'hide.', 1157: 'hiding', 1158: 'high', 1159: 'high.', 1160: 'hill.', 1161: 'him', 1162: 'him,', 1163: 'him,\"', 1164: 'him.', 1165: 'him.\"', 1166: 'him?\"', 1167: 'himself.', 1168: 'his', 1169: 'his.', 1170: 'hit', 1171: 'hold', 1172: 'hold.', 1173: 'holding', 1174: 'holds', 1175: 'hole', 1176: 'hole!\"', 1177: 'hole,', 1178: 'hole.', 1179: 'holes', 1180: 'home', 1181: 'home!\"', 1182: 'home,', 1183: 'home.', 1184: 'home.\"', 1185: 'honest', 1186: 'honey.', 1187: 'hop', 1188: 'hop.', 1189: 'hoped', 1190: 'hopped', 1191: 'hopping', 1192: 'horse.', 1193: 'hose.', 1194: 'hot', 1195: 'house', 1196: 'house,', 1197: 'house.', 1198: 'houses,', 1199: 'how', 1200: 'howled', 1201: 'hug', 1202: 'hug.', 1203: 'huge', 1204: 'huge,', 1205: 'hugged', 1206: 'hugged,', 1207: 'hugged.', 1208: 'hung', 1209: 'hungry', 1210: 'hungry.', 1211: 'hunter', 1212: 'hunter.', 1213: 'hurry', 1214: 'hurt', 1215: 'hurt.', 1216: 'husband', 1217: 'husband,', 1218: 'ice', 1219: 'idea', 1220: 'idea,\"', 1221: 'idea.', 1222: 'if', 1223: 'ignore', 1224: 'imagination.\"', 1225: 'imagined', 1226: 'important', 1227: 'in', 1228: 'in!', 1229: 'in.', 1230: 'include', 1231: 'included', 1232: 'incredible', 1233: 'insect', 1234: 'insect.', 1235: 'inside', 1236: 'inside,', 1237: 'inside.', 1238: 'inside.\"', 1239: 'insisted,', 1240: 'inspired!', 1241: 'intelligent', 1242: 'interested', 1243: 'into', 1244: 'is', 1245: 'is!”', 1246: 'is.', 1247: 'island,', 1248: 'island.', 1249: 'it', 1250: 'it!', 1251: 'it!\"', 1252: \"it's\", 1253: 'it,', 1254: 'it,\"', 1255: 'it.', 1256: 'it.\"', 1257: 'it?\"', 1258: 'it?”', 1259: 'its', 1260: 'jail', 1261: 'jail,', 1262: 'jealous', 1263: 'job', 1264: 'job!\"', 1265: 'job,', 1266: 'job.\"', 1267: 'jog', 1268: 'join', 1269: 'joined', 1270: 'journey.', 1271: 'joy', 1272: 'juice', 1273: 'juice.', 1274: 'jump', 1275: 'jump,', 1276: 'jumped', 1277: 'jumped.', 1278: 'jumping.', 1279: 'jungle.', 1280: 'just', 1281: 'keep', 1282: 'kept', 1283: 'key', 1284: 'kicked', 1285: 'kid.', 1286: 'kids', 1287: 'kids,', 1288: 'kids.', 1289: 'kind', 1290: 'kind,', 1291: 'kind.', 1292: 'kinds', 1293: 'king', 1294: 'kiss', 1295: 'kiss.', 1296: 'kissed', 1297: 'kitchen', 1298: 'kitchen.', 1299: 'knee', 1300: 'knee.', 1301: 'kneeled', 1302: 'kneeling,', 1303: 'knew', 1304: 'knocks', 1305: 'know', 1306: 'know,', 1307: 'know.', 1308: 'knowing', 1309: 'known', 1310: 'knows', 1311: 'label', 1312: 'label.', 1313: 'lake.', 1314: 'landed', 1315: 'landscape', 1316: 'landscape,', 1317: 'language.', 1318: 'languages,', 1319: 'large', 1320: 'last', 1321: 'last,', 1322: 'late,', 1323: 'later.', 1324: 'later?\"', 1325: 'laugh', 1326: 'laugh.', 1327: 'laughed', 1328: 'laughed,', 1329: 'laughed.', 1330: 'laughing', 1331: 'laughing.', 1332: 'law!', 1333: 'lead', 1334: 'leaf', 1335: 'leaf,', 1336: 'leaf.', 1337: 'leaned', 1338: 'learn', 1339: 'learned', 1340: 'learning', 1341: 'learnt', 1342: 'leather', 1343: 'leather.', 1344: 'leaves', 1345: 'leaves.', 1346: 'led', 1347: 'left', 1348: 'left,', 1349: 'leg', 1350: 'legs.', 1351: 'less', 1352: 'less.', 1353: 'lesson', 1354: 'let', 1355: \"let's\", 1356: 'letters', 1357: 'letting', 1358: 'library', 1359: 'library,', 1360: 'library.', 1361: 'licked', 1362: 'licks', 1363: 'life', 1364: 'lighter', 1365: 'like', 1366: 'liked', 1367: 'likes', 1368: 'lion', 1369: \"lion's\", 1370: 'lion.', 1371: 'lions', 1372: 'lions.', 1373: 'lips.', 1374: 'listen', 1375: 'listen.', 1376: 'listened', 1377: 'listened.', 1378: 'listening', 1379: 'little', 1380: 'live?\"', 1381: 'lived', 1382: 'lives', 1383: 'living', 1384: 'local', 1385: 'lock', 1386: 'log.', 1387: 'lonely', 1388: 'long', 1389: 'long.', 1390: 'look', 1391: 'look!\"', 1392: 'look.', 1393: 'looked', 1394: 'looking', 1395: 'looking,', 1396: 'looking.', 1397: 'looks', 1398: 'lose', 1399: 'lost', 1400: 'lost.', 1401: 'lot', 1402: 'lot.', 1403: 'lots', 1404: 'loud', 1405: 'loud.', 1406: 'loudly.', 1407: 'love', 1408: 'love.', 1409: 'loved', 1410: 'lovely', 1411: 'loves,\"', 1412: 'loyal', 1413: 'lucky', 1414: 'lying', 1415: 'mad.', 1416: 'made', 1417: 'made.', 1418: 'magic', 1419: 'magical', 1420: 'mailbox', 1421: 'mailbox.', 1422: 'make', 1423: 'makes', 1424: 'making', 1425: 'man', 1426: \"man's\", 1427: 'man,', 1428: 'man.', 1429: 'many', 1430: 'map', 1431: 'map!', 1432: 'map.', 1433: 'march', 1434: 'markers', 1435: 'market', 1436: 'market.', 1437: 'masterpiece.', 1438: 'match', 1439: 'matches', 1440: 'matey!\"', 1441: 'matter', 1442: 'maze', 1443: 'maze.', 1444: 'me', 1445: 'me,', 1446: 'me,\"', 1447: 'me.', 1448: 'me.\"', 1449: 'meadow', 1450: 'mean', 1451: 'mean,', 1452: 'measure', 1453: 'measure.', 1454: 'measuring', 1455: 'meet', 1456: 'meeting', 1457: 'melt', 1458: 'melt,\"', 1459: 'melt.', 1460: 'mess.', 1461: 'messy', 1462: 'met', 1463: 'middle', 1464: 'might', 1465: 'mill', 1466: 'mill!\"', 1467: 'mill,\"', 1468: 'mill.', 1469: 'mill.\"', 1470: 'mine,', 1471: 'mine.', 1472: 'mint', 1473: 'mint,', 1474: 'mint.', 1475: 'mint?\"', 1476: 'mistake,', 1477: 'mistake.', 1478: 'mistakes.', 1479: 'modern', 1480: 'modest', 1481: 'mom', 1482: 'mom!', 1483: \"mom's\", 1484: 'mom,', 1485: 'mom,\"', 1486: 'mom.', 1487: 'moment', 1488: 'moment.', 1489: 'momma', 1490: 'mommy', 1491: 'money', 1492: 'monster', 1493: 'monster.', 1494: 'moral', 1495: 'more', 1496: 'more!', 1497: 'more.', 1498: 'morning,', 1499: 'most', 1500: 'mother', 1501: 'motivation', 1502: 'mouse', 1503: 'mouth!', 1504: 'mouth.', 1505: 'move', 1506: 'move.', 1507: 'moving.', 1508: 'moving.\"', 1509: 'much', 1510: 'much,', 1511: 'much.', 1512: 'mum', 1513: 'music.', 1514: 'musician', 1515: 'must', 1516: 'my', 1517: 'mysterious', 1518: 'name', 1519: 'named', 1520: 'naug', 1521: 'naughty', 1522: 'near', 1523: 'nearby', 1524: 'neck', 1525: 'neck.', 1526: 'need', 1527: 'needed', 1528: 'needle.', 1529: 'needs', 1530: \"neighbor's\", 1531: 'never', 1532: 'new', 1533: 'new.', 1534: 'next', 1535: 'nice', 1536: 'nice,\"', 1537: 'nice.', 1538: 'nice.\"', 1539: 'night,', 1540: 'night.', 1541: 'no', 1542: 'no!', 1543: 'no!\"', 1544: 'no,', 1545: 'nodded', 1546: 'nodded.', 1547: 'nods', 1548: 'nods.', 1549: 'noise', 1550: 'noise.', 1551: 'noises', 1552: 'noises.', 1553: 'none', 1554: 'none.', 1555: 'noon.', 1556: 'normal', 1557: 'nose', 1558: 'nose.', 1559: 'not', 1560: 'note', 1561: 'note!', 1562: 'note.', 1563: 'note.\"', 1564: 'nothing.', 1565: 'noticed', 1566: 'now', 1567: 'now\".', 1568: 'now.', 1569: 'nowhere,', 1570: 'number', 1571: 'observe', 1572: 'ocean.', 1573: 'of', 1574: 'off', 1575: 'off.', 1576: 'office.', 1577: 'okay,', 1578: 'okay,\"', 1579: 'okay.', 1580: 'okay?\"', 1581: 'old', 1582: 'on', 1583: 'on,', 1584: 'on.', 1585: 'one', 1586: 'one,', 1587: 'one,\"', 1588: 'one.', 1589: 'one.\"', 1590: 'only', 1591: 'onto', 1592: 'open', 1593: 'open\".', 1594: 'opened', 1595: 'opens', 1596: 'opinion?\"', 1597: 'or', 1598: 'orange', 1599: 'orange,', 1600: 'orange.', 1601: 'order', 1602: 'other', 1603: \"other's\", 1604: 'other.', 1605: 'others', 1606: 'others,', 1607: 'others.', 1608: 'otter', 1609: 'our', 1610: 'out', 1611: 'out!\"', 1612: 'out,\"', 1613: 'out.', 1614: 'out.\"', 1615: 'outside', 1616: 'outside!”', 1617: 'outside,', 1618: 'outside.', 1619: 'outside.\"', 1620: 'outside.”', 1621: 'over', 1622: 'over.', 1623: 'own!', 1624: 'oxygen,', 1625: 'packages.', 1626: 'packed', 1627: 'pain.', 1628: 'paint', 1629: 'painted', 1630: 'pair', 1631: 'pale', 1632: 'paper', 1633: 'paper,', 1634: 'park', 1635: 'park!', 1636: 'park!\"', 1637: 'park,', 1638: 'park.', 1639: 'part.\"', 1640: 'party', 1641: 'passed', 1642: 'past', 1643: 'patch', 1644: 'patch.', 1645: 'path', 1646: 'path.', 1647: 'paths.', 1648: 'patient', 1649: 'paw', 1650: 'paws,', 1651: 'pay', 1652: 'peace', 1653: 'peace.', 1654: 'peace.\"', 1655: 'peaceful', 1656: 'peel', 1657: 'peel.', 1658: 'pen', 1659: 'people', 1660: 'perfect', 1661: 'perfect.', 1662: 'perform', 1663: 'permit', 1664: 'persistent', 1665: 'persistent.', 1666: 'person', 1667: 'pet', 1668: 'pet.', 1669: 'pick', 1670: 'picked', 1671: 'picking', 1672: 'picnic', 1673: 'picnic!\"', 1674: 'picture', 1675: 'picture.', 1676: 'pie', 1677: 'piece', 1678: 'pieces,', 1679: 'pieces.', 1680: 'pigs,', 1681: 'pinched', 1682: 'pink', 1683: 'pirate', 1684: 'pirate.', 1685: 'pirates', 1686: 'pirates.', 1687: 'place', 1688: 'place,', 1689: 'place.', 1690: 'place?\"', 1691: 'plan.', 1692: 'planned', 1693: 'plant', 1694: 'plant.', 1695: 'plastic', 1696: 'play', 1697: 'play!\"', 1698: 'play.', 1699: 'play?\"', 1700: 'played', 1701: 'played,', 1702: 'played.', 1703: 'playing', 1704: 'playing,', 1705: 'playing.', 1706: 'please', 1707: 'please!\"', 1708: 'please?\"', 1709: 'point', 1710: 'pointing', 1711: 'poke', 1712: 'poked', 1713: 'polite', 1714: 'polite.\"', 1715: 'pond', 1716: 'pond.', 1717: 'poor', 1718: 'possession.', 1719: 'possible.', 1720: 'post', 1721: 'post.', 1722: 'postman.', 1723: 'pot.', 1724: 'powder', 1725: 'powder.', 1726: 'powder?\"', 1727: 'power', 1728: 'powerful', 1729: 'pretend', 1730: 'pretend.', 1731: 'pretty', 1732: 'pretty!\"', 1733: 'pretty,', 1734: 'pretty.', 1735: 'pretty?\"', 1736: 'prevent', 1737: 'pride', 1738: 'prized', 1739: 'problem,', 1740: 'promise', 1741: 'promised', 1742: 'protect', 1743: 'proud', 1744: 'proudly', 1745: 'pulled', 1746: 'pulling', 1747: 'pumpkin', 1748: 'pumpkin,', 1749: 'pumpkin.', 1750: 'pumpkins', 1751: 'pumpkins.', 1752: 'pumpkins.\"', 1753: 'pumpkins?\"', 1754: 'puppy', 1755: 'puppy,', 1756: 'puppy.', 1757: 'push', 1758: 'pushed', 1759: 'put', 1760: 'puts', 1761: 'puzzle', 1762: 'puzzle.', 1763: 'puzzle?\"', 1764: 'quarrel,', 1765: 'questioned', 1766: 'quickly', 1767: 'quiet', 1768: 'quite', 1769: 'rabbit', 1770: 'rabbit.', 1771: 'race', 1772: 'race,', 1773: 'race.', 1774: 'raced', 1775: 'rag', 1776: 'rag.', 1777: 'rain', 1778: 'rain!', 1779: 'rain.', 1780: 'rainbow', 1781: 'raining.', 1782: 'ran', 1783: 'rang,', 1784: 'rang.', 1785: 'rat', 1786: 'reach', 1787: 'reached', 1788: 'read', 1789: 'read.', 1790: 'ready', 1791: 'ready,', 1792: 'real', 1793: 'real,', 1794: 'realised', 1795: 'realized', 1796: 'really', 1797: 'recognized', 1798: 'red', 1799: 'red,', 1800: 'regret', 1801: 'relax', 1802: 'reliable', 1803: 'reliable.', 1804: 'relieved', 1805: 'rely', 1806: 'remember', 1807: 'remembered', 1808: 'reminder', 1809: 'repair', 1810: 'replied,', 1811: 'rest', 1812: 'rest.', 1813: 'restless', 1814: 'restored', 1815: 'rich.', 1816: 'rid', 1817: 'riding', 1818: 'right', 1819: 'right!', 1820: 'right,\"', 1821: 'right.', 1822: 'ring', 1823: 'ringing', 1824: 'rises!\"', 1825: 'river', 1826: 'river,', 1827: 'river.', 1828: 'river?!\"', 1829: 'roar', 1830: 'roar,', 1831: 'roar.', 1832: 'roared', 1833: 'rock', 1834: 'rock!\"', 1835: 'rock.', 1836: 'rocks.', 1837: 'room', 1838: 'room.', 1839: 'round', 1840: 'rubber', 1841: 'rude', 1842: 'ruined', 1843: 'run', 1844: 'run,', 1845: 'run.', 1846: 'running', 1847: 'running,', 1848: 'runs', 1849: 'rushed', 1850: 'sad', 1851: 'sad,', 1852: 'sad.', 1853: 'sad?\"', 1854: 'safe', 1855: 'safe.', 1856: 'safe.\"', 1857: 'said', 1858: 'said,', 1859: 'said.', 1860: 'said:', 1861: 'sail', 1862: 'sailed', 1863: 'sailor', 1864: 'sale,\"', 1865: 'same', 1866: 'sand', 1867: 'sandbox', 1868: 'sandbox,', 1869: 'sandbox.', 1870: 'sat', 1871: 'saw', 1872: 'say', 1873: 'say.', 1874: 'says', 1875: 'says,', 1876: 'says.', 1877: 'scare', 1878: 'scared', 1879: 'scared,', 1880: 'scared.', 1881: 'scarf', 1882: 'scarf,', 1883: 'scarf.', 1884: 'scarf?\"', 1885: 'scary', 1886: 'scissors', 1887: 'sculpture.', 1888: 'sea', 1889: 'sea.', 1890: 'search,', 1891: 'season.', 1892: 'secret', 1893: 'see', 1894: 'see?\"', 1895: 'seeing', 1896: 'seem', 1897: 'seen', 1898: 'seen!', 1899: 'sees', 1900: 'send?\"', 1901: 'serious', 1902: 'set,', 1903: 'shade', 1904: 'shade.', 1905: 'shake.', 1906: 'shakes', 1907: 'shapes.', 1908: 'share', 1909: 'shared', 1910: 'sharing', 1911: 'sharp', 1912: 'she', 1913: 'shelf.', 1914: 'shell', 1915: 'shell.', 1916: 'shells', 1917: 'shells.', 1918: 'shelter', 1919: 'shining', 1920: 'shiny', 1921: 'shiny.', 1922: 'ship', 1923: 'ship.', 1924: 'ship.\"', 1925: 'shoes', 1926: 'shone', 1927: 'shook', 1928: 'shoot.', 1929: 'shopkeeper', 1930: 'shopping.', 1931: 'should', 1932: 'shouted,', 1933: 'shouted.', 1934: 'shovel.', 1935: 'shovels.', 1936: 'show', 1937: 'showed', 1938: 'shows', 1939: 'shrugged', 1940: 'side', 1941: 'sighed.', 1942: 'sign', 1943: 'sing', 1944: 'singing.', 1945: 'sister', 1946: 'sister,', 1947: 'sister.', 1948: 'sisters,', 1949: 'sit', 1950: 'sitting', 1951: 'skull', 1952: 'skull!', 1953: 'skull.', 1954: 'sky.', 1955: 'sleep', 1956: 'sleep,', 1957: 'sleep.', 1958: 'sleepy', 1959: 'slid', 1960: 'slide', 1961: 'slide,', 1962: 'slide.', 1963: 'sliding', 1964: 'slipped', 1965: 'slipped.', 1966: 'slow.', 1967: 'small', 1968: 'small,', 1969: 'small.', 1970: 'smaller', 1971: 'smaller.', 1972: 'smart.', 1973: 'smell', 1974: 'smelled', 1975: 'smells.', 1976: 'smile', 1977: 'smile,', 1978: 'smile.', 1979: 'smiled', 1980: 'smiled,', 1981: 'smiled.', 1982: 'smiles', 1983: 'smiles.', 1984: 'smoke', 1985: 'smooth', 1986: 'snack', 1987: 'snack.', 1988: 'sneaky.', 1989: 'snow', 1990: 'snow.', 1991: 'snowball', 1992: 'snowballs.', 1993: 'snowman', 1994: 'snowman,', 1995: 'snowman.', 1996: 'snowman?', 1997: 'so', 1998: 'so,', 1999: 'so.', 2000: 'soccer', 2001: 'soccer.', 2002: 'soft', 2003: 'soft.', 2004: 'softly', 2005: 'some', 2006: 'someone', 2007: 'something', 2008: 'something.', 2009: 'sometimes', 2010: 'sometimes,', 2011: 'son', 2012: 'song', 2013: 'song.', 2014: 'songs', 2015: 'soon', 2016: 'soon!\"', 2017: 'soon,', 2018: 'sooner', 2019: 'sorry', 2020: 'sorry,', 2021: 'sorry.', 2022: 'sound', 2023: 'sound,', 2024: 'sound.', 2025: 'sounds', 2026: 'sounds.', 2027: 'sparkly.', 2028: 'spat', 2029: 'speak.', 2030: 'spear', 2031: 'spear.', 2032: 'special', 2033: 'special.', 2034: 'spent', 2035: 'spicy.', 2036: 'spills', 2037: 'spirit', 2038: 'spirit,', 2039: 'spirit.', 2040: 'splash', 2041: 'split', 2042: 'spoke', 2043: 'sport', 2044: 'sport.', 2045: 'spot', 2046: 'spot.', 2047: 'sprayed', 2048: 'squash', 2049: 'squash,', 2050: 'squash.', 2051: 'squirrel', 2052: 'squirrel.', 2053: 'stamped', 2054: 'start', 2055: 'started', 2056: 'started,', 2057: 'starting', 2058: 'starts', 2059: 'stay', 2060: 'stay.', 2061: 'stay.\"', 2062: 'stayed', 2063: 'stepped', 2064: 'steps', 2065: 'stick', 2066: 'sticks.', 2067: 'still', 2068: 'still.', 2069: 'stomp', 2070: 'stomped', 2071: 'stone', 2072: 'stone.', 2073: 'stones', 2074: 'stood', 2075: 'stop', 2076: 'stop!\"', 2077: 'stop,\"', 2078: 'stop.', 2079: 'stopped', 2080: 'store', 2081: 'store!', 2082: 'store.', 2083: 'stories', 2084: 'story', 2085: 'story.', 2086: 'strange', 2087: 'strange.', 2088: 'strings.', 2089: 'strong', 2090: 'strong.', 2091: 'struck', 2092: 'stubborn', 2093: 'stubborn,', 2094: 'stuck.', 2095: 'stupid', 2096: 'stupid!', 2097: 'stupid.', 2098: 'succeed.', 2099: 'such', 2100: 'suddenly', 2101: 'suddenly,', 2102: 'suggested', 2103: 'summer', 2104: 'sun', 2105: 'sun.', 2106: 'sunglasses', 2107: 'sunglasses.', 2108: 'sunlight', 2109: 'sunny', 2110: 'sunshine', 2111: 'supposed', 2112: 'sure', 2113: 'surface', 2114: 'surface.', 2115: 'surfaced,', 2116: 'surprise,', 2117: 'surprise.', 2118: 'surprised', 2119: 'surprised.', 2120: 'surrounding', 2121: 'swam', 2122: 'sweet', 2123: 'sweet-smelling', 2124: 'swim', 2125: 'swimming', 2126: 'swing', 2127: 'swing,', 2128: 'swing.', 2129: 'swing.\"', 2130: 'swinging', 2131: 'swings', 2132: 'swings.', 2133: 'swung', 2134: 'table.', 2135: 'tag', 2136: 'tail', 2137: 'tail.', 2138: 'tails,', 2139: 'take', 2140: 'takes', 2141: 'taking', 2142: 'talk.', 2143: 'talked', 2144: 'talking', 2145: 'talking,', 2146: 'tall', 2147: 'tall,', 2148: 'tall.', 2149: 'tallest', 2150: 'tap!\"', 2151: 'tap.', 2152: 'taste', 2153: 'teach', 2154: 'teddy', 2155: 'teeth', 2156: 'teeth.', 2157: 'television,', 2158: 'television.', 2159: 'tell', 2160: 'telling', 2161: 'terrible', 2162: 'terrible!', 2163: 'terrible,', 2164: 'texture,', 2165: 'than', 2166: 'thank', 2167: 'thanked', 2168: 'that', 2169: \"that's\", 2170: 'that,', 2171: 'that.', 2172: 'the', 2173: 'their', 2174: 'them', 2175: 'them.', 2176: 'them.\"', 2177: 'then', 2178: 'then,', 2179: 'there', 2180: 'there!\"', 2181: 'there,', 2182: 'there.', 2183: 'there?\"', 2184: 'they', 2185: 'thing', 2186: 'thing!', 2187: 'things', 2188: 'things,', 2189: 'things.', 2190: 'things.\"', 2191: 'think', 2192: 'thinks', 2193: 'this', 2194: 'this\".', 2195: 'this,\"', 2196: 'those', 2197: 'thought', 2198: 'thought,', 2199: 'three', 2200: 'three,', 2201: 'three,\"', 2202: 'three-year-old', 2203: 'threw', 2204: 'throat.', 2205: 'through', 2206: 'throwing', 2207: 'thumb', 2208: 'thumb!', 2209: 'tickles!\"', 2210: 'tiger', 2211: 'tiger.', 2212: 'tight', 2213: 'tightly,', 2214: 'time', 2215: 'time,', 2216: 'time.', 2217: 'time.\"', 2218: 'times', 2219: 'times.', 2220: 'tiny', 2221: 'tired', 2222: 'tired.', 2223: 'to', 2224: 'to.', 2225: 'today', 2226: 'today!\"', 2227: 'today?!\"', 2228: 'together', 2229: 'together,', 2230: 'together.', 2231: 'together.\"', 2232: 'toilet', 2233: 'toilet!\"', 2234: 'toilet.\"', 2235: 'told', 2236: 'tomorrow.\"', 2237: 'tongue.', 2238: 'too', 2239: 'too!\"', 2240: 'too,', 2241: 'too.', 2242: 'too.\"', 2243: 'too?\"', 2244: 'took', 2245: 'top', 2246: 'touch', 2247: 'touched', 2248: 'tough', 2249: 'tough.', 2250: 'towards', 2251: 'tower.', 2252: 'town', 2253: 'town,', 2254: 'town.', 2255: 'toy', 2256: 'toy,', 2257: 'toy.', 2258: 'toys', 2259: 'toys.', 2260: 'toys:', 2261: 'treasure', 2262: 'treasure!', 2263: 'treasure.', 2264: 'treats!', 2265: 'tree', 2266: 'tree,', 2267: 'tree.', 2268: 'trees', 2269: 'trick', 2270: 'tried', 2271: 'tried,', 2272: 'tries,', 2273: 'trip', 2274: 'trips', 2275: 'truck', 2276: 'trumpet', 2277: 'trumpet.', 2278: 'trumpet?\"', 2279: 'truth.', 2280: 'try', 2281: 'try,', 2282: 'try.', 2283: 'try?\"', 2284: 'trying', 2285: 'trying,', 2286: 'tugged', 2287: 'tummy', 2288: 'tummy.', 2289: 'tunnel.', 2290: 'turn', 2291: 'turn,', 2292: 'turn.', 2293: 'turned', 2294: 'turns', 2295: 'turns,\"', 2296: 'turtle.', 2297: 'tweet!', 2298: 'twins', 2299: 'twisty', 2300: 'two', 2301: 'two!\"', 2302: 'two,', 2303: 'ugly.', 2304: 'under', 2305: 'underneath', 2306: 'understand', 2307: 'understand.', 2308: 'understanding', 2309: 'unexpected', 2310: 'unexpected.', 2311: 'unhappy', 2312: 'unknown', 2313: 'unlock', 2314: 'unlocked', 2315: 'until', 2316: 'up', 2317: 'up,', 2318: 'up.', 2319: 'up.\"', 2320: 'upon', 2321: 'us', 2322: 'us.”', 2323: 'use', 2324: 'used', 2325: 'using', 2326: 'usual.', 2327: 'vase', 2328: 'vase!', 2329: 'vase.', 2330: 'vases', 2331: 'very', 2332: 'vibrations', 2333: 'victory', 2334: 'victory.', 2335: 'visit', 2336: 'voice', 2337: 'wagged', 2338: 'wags', 2339: 'wait', 2340: 'waited', 2341: 'waiting', 2342: 'walk', 2343: 'walk.', 2344: 'walked', 2345: 'walked,', 2346: 'walking', 2347: 'want', 2348: 'want!', 2349: 'wanted', 2350: 'wanting', 2351: 'warm', 2352: 'warm.', 2353: 'warn', 2354: 'was', 2355: 'was,', 2356: 'was.', 2357: 'wash.', 2358: \"wasn't\", 2359: 'watch', 2360: 'watched', 2361: 'water', 2362: 'water,', 2363: 'water.', 2364: 'watered', 2365: 'waters', 2366: 'wave', 2367: 'waved', 2368: 'waves.', 2369: 'way', 2370: 'ways', 2371: 'we', 2372: \"we're\", 2373: 'wealthy', 2374: 'wear', 2375: 'wearing', 2376: 'weather', 2377: 'weighed', 2378: 'weighing', 2379: 'weird', 2380: 'welcome,', 2381: 'welcome,\"', 2382: 'welcome.', 2383: 'well.', 2384: 'went', 2385: 'went.', 2386: 'were', 2387: 'wet', 2388: 'wet.', 2389: 'what', 2390: 'wheat', 2391: 'wheat!', 2392: 'wheat.', 2393: 'wheel', 2394: 'when', 2395: 'where', 2396: 'which', 2397: 'while', 2398: 'while,', 2399: 'while.', 2400: 'white', 2401: 'white!\"', 2402: 'white.', 2403: 'who', 2404: 'whole', 2405: 'wild.', 2406: 'will', 2407: 'will.\"', 2408: 'win', 2409: 'win,', 2410: 'win.', 2411: 'wind', 2412: 'window', 2413: 'winter?\"', 2414: 'wise', 2415: 'with', 2416: 'with.', 2417: 'without', 2418: 'wobbled', 2419: 'woman', 2420: 'won', 2421: \"won't\", 2422: 'won\\'t,\"', 2423: 'wonder', 2424: 'wonderful', 2425: 'wood', 2426: 'wood.', 2427: 'woods', 2428: 'woods.', 2429: 'words.', 2430: 'work', 2431: 'work.', 2432: 'worked', 2433: 'worked.', 2434: 'world', 2435: 'world.', 2436: 'worried', 2437: 'worried.', 2438: 'worry', 2439: 'worry,', 2440: 'worry.', 2441: 'would', 2442: \"wouldn't\", 2443: 'wrapped', 2444: 'written', 2445: 'wrong!', 2446: 'wrong.', 2447: 'yard', 2448: 'yard.', 2449: 'yarn', 2450: 'years,', 2451: 'years.', 2452: 'yelled', 2453: 'yelled,', 2454: 'yellow', 2455: 'yellow.', 2456: 'yells.', 2457: 'you', 2458: 'you!\"', 2459: \"you're\", 2460: 'you,', 2461: 'you,\"', 2462: 'you.', 2463: 'you.\"', 2464: 'you?\"', 2465: 'young', 2466: 'your', 2467: 'yours!\"', 2468: 'yours,', 2469: 'you”.', 2470: 'yucky', 2471: 'yucky!', 2472: 'yummy', 2473: 'zone', 2474: 'zoom', 2475: 'zoomed', 2476: '–', 2477: '“I', 2478: '“It’s', 2479: '“Let’s', 2480: '“Look', 2481: '“No,', 2482: '“Of', 2483: '“The', 2484: '“Wow,'}\n","[599, 1870]\n","cat sat\n"]}]},{"cell_type":"code","source":["tiny_X = torch.tensor([[1, 3, 4, 5, 6, 3, 7, 0, 0, 0, 0, 0]])\n","tiny_y = torch.tensor([[3, 4, 5, 6, 3, 7, 2, 0, 0, 0, 0, 0]])\n","\n","# Generate some very simple data to test\n","story_input = '<s> the cat sat on the mat <pad> <pad> <pad>'\n","print(story_input.split())\n","story_target = 'the cat sat on the mat </s> <pad> <pad> <pad>'\n","print(story_target.split())\n","\n","tiny_X = torch.tensor(tokenizer.encode(story_input))\n","tiny_y = torch.tensor(tokenizer.encode(story_target))\n","print(tiny_X)\n","print(tiny_y)\n"],"metadata":{"id":"7sXKyQEvCGSj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","    def __init__(self, stories):\n","        self.x = [s.strip() for s in stories.split('\\n') if s.strip()]\n","        self.y = self.x[:]\n","        self.tokenizer = Tokenizer()\n","        #self.sp = spm.SentencePieceProcessor()\n","\n","    def __len__(self):\n","        return len(self.x)\n","\n","    def __getitem__(self, idx):\n","        #print(self.x[idx])\n","        x_encoded = self.tokenizer.encode(self.x[idx])\n","        y_encoded = self.tokenizer.encode(self.y[idx])\n","        #print(x_encoded)\n","        #x_check = self.tokenizer.decode(x_encoded)\n","        #y_check = self.tokenizer.decode(y_encoded)\n","        #print(x_check)\n","\n","        #x_encoded = self.sp.encode(self.x[idx])\n","        #y_encoded = self.sp.encode(self.y[idx])\n","\n","        # Add <s> and </s> tokens\n","        x_tensor = torch.tensor([1] + x_encoded)\n","        y_tensor = torch.tensor(y_encoded + [2])\n","\n","        return [x_tensor, y_tensor]\n"],"metadata":{"id":"gHz4yrbELGqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        # Ensure that the model dimension (d_model) is divisible by the number of heads\n","        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n","\n","        # Initialize dimensions\n","        self.d_model = d_model # Model's dimension\n","        self.num_heads = num_heads # Number of attention heads\n","        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n","\n","        # Linear layers for transforming inputs\n","        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n","        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n","        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n","        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        # Calculate attention scores\n","        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","\n","        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n","        if mask is not None:\n","            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n","\n","        # Softmax is applied to obtain attention probabilities\n","        attn_probs = torch.softmax(attn_scores, dim=-1)\n","\n","        # Multiply by values to obtain the final output\n","        output = torch.matmul(attn_probs, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        # Reshape the input to have num_heads for multi-head attention\n","        batch_size, seq_length, d_model = x.size()\n","        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        # Combine the multiple heads back to original shape\n","        batch_size, _, seq_length, d_k = x.size()\n","        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n","\n","    def forward(self, Q, K, V, mask=None):\n","        # Apply linear transformations and split heads\n","        Q = self.split_heads(self.W_q(Q))\n","        K = self.split_heads(self.W_k(K))\n","        V = self.split_heads(self.W_v(V))\n","        # Perform scaled dot-product attention\n","        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n","        # Combine heads and apply output transformation\n","        output = self.W_o(self.combine_heads(attn_output))\n","        return output\n"],"metadata":{"id":"lNp3jfdLbKQ_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionWiseFeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super(PositionWiseFeedForward, self).__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)\n","        self.fc2 = nn.Linear(d_ff, d_model)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.relu(self.fc1(x)))"],"metadata":{"id":"mj-OcY9ObGY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_seq_length):\n","        super(PositionalEncoding, self).__init__()\n","\n","        pe = torch.zeros(max_seq_length, d_model)\n","        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.register_buffer('pe', pe.unsqueeze(0))\n","\n","    def forward(self, x):\n","        return x + self.pe[:, :x.size(1)]"],"metadata":{"id":"GDuk_XBCbEsd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout):\n","        super(DecoderLayer, self).__init__()\n","        self.self_attn = MultiHeadAttention(d_model, num_heads)\n","        #self.cross_attn = MultiHeadAttention(d_model, num_heads)\n","        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, x_mask):\n","        # Next line is the issue\n","        attn_output = self.self_attn(x, x, x, x_mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        ff_output = self.feed_forward(x)\n","        x = self.norm2(x + self.dropout(ff_output))\n","        return x"],"metadata":{"id":"BC0Mx4fRaFEN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MySimpleTransformer(nn.Module):\n","    def __init__(self, vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n","        super(MySimpleTransformer, self).__init__()\n","        self.decoder_embedding = nn.Embedding(vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n","        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc = nn.Linear(d_model, vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def generate_mask(self, x):\n","        # Create a boolean tensor where True indicates non-zero elements and False indicates zero elements\n","        x_mask = (x != 0).unsqueeze(1).unsqueeze(3)\n","\n","        seq_length = x.size(1)\n","        nopeek_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n","        x_mask = x_mask & nopeek_mask\n","        return x_mask\n","\n","    def forward(self, x, mask=False):\n","        # Generate mask only during training\n","        if mask:\n","            x_mask = self.generate_mask(x)\n","        else:\n","            x_mask = None\n","\n","        x_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(x)))\n","\n","        for dec_layer in self.decoder_layers:\n","            dec_output = dec_layer(x_embedded, x_mask)\n","\n","        # Run the output through a fully connected layer\n","        output = self.fc(dec_output)\n","\n","        # Apply softmax activation function along the last dimension\n","        output = F.softmax(output, dim=-1)\n","\n","        return output"],"metadata":{"id":"XHsAquwFaFIj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def padding_fn(batch):\n","\n","    # Unpack the batch into x and y tensors\n","    x_batch, y_batch = zip(*batch)\n","\n","    # Pad sequences and labels to the same length\n","    padded_x = pad_sequence(x_batch, batch_first=True, padding_value=0)\n","    padded_y = pad_sequence(y_batch, batch_first=True, padding_value=0)\n","\n","    return padded_x, padded_y\n"],"metadata":{"id":"iv5R77haz6Di"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_seq_length = 211\n","d_model = 56\n","num_heads = 1\n","num_layers = 1\n","d_ff = 1\n","dropout = 0.1\n","learning_rate = 0.01\n","num_epochs = 10\n","batch_size = 8\n","\n","'''\n","with open(train_set_path, 'r') as file:\n","    # Read the entire contents of the file into a single string\n","    train_stories = file.read()\n","\n","with open(val_set_path, 'r') as file:\n","    # Read the entire contents of the file into a single string\n","    val_stories = file.read()\n","'''\n","\n","\n","\n","with open(train_set_path, 'r') as file:\n","    # Read the entire contents of the file into a single string\n","    train_stories = val_stories = file.read()\n","\n","\n","\n","# Create the datasets and the data loaders\n","train_dataset = CustomDataset(train_stories)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=padding_fn)\n","\n","val_dataset = CustomDataset(val_stories)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, collate_fn=padding_fn)\n","\n","# Create the model, loss function and optimizer\n","transformer = MySimpleTransformer(vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n","criterion = nn.CrossEntropyLoss(reduction='sum', ignore_index=0)  # ignore_index=0 will ensure that padding is ignored\n","optimizer = Adam(transformer.parameters(), lr=learning_rate)\n","\n","# Set the transformer model to training mode, enabling behaviors like dropout\n","transformer.train()\n","\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(transformer):,} trainable parameters')"],"metadata":{"id":"6X_fiLxsuNVi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712566473513,"user_tz":-60,"elapsed":3926,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"6f181d1d-846b-4577-a7a0-78b184ff03fa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 293,966 trainable parameters\n"]}]},{"cell_type":"code","source":["sos = torch.tensor([1])\n","eos = torch.tensor([2])\n","\n","# Initialize early stopping parameters\n","patience = 5\n","best_val_loss = float('inf')\n","epochs_without_improvement = 0\n","best_model_state = None\n","\n","epoch_train_loss = []\n","epoch_val_loss = []\n","for epoch in tqdm(range(num_epochs)):\n","\n","    print(\"START_EPOCH\")\n","\n","    # Training phase\n","    transformer.train()\n","\n","    batch_train_loss = []\n","    for batch in train_dataloader:\n","\n","        # Unpack the batch into x and y tensors\n","        x_batch, y_batch = batch\n","\n","        optimizer.zero_grad()\n","        output = transformer(x_batch, mask=True)\n","\n","        #print(output.shape)\n","\n","        output_tensor = output.view(-1, output.size(2))\n","        y_tensor = y_batch.view(-1)\n","\n","        loss = criterion(output_tensor, y_tensor)\n","        batch_train_loss.append(loss.item())\n","        loss.backward()\n","        optimizer.step()\n","\n","    # Compute training loss for the epoch\n","    train_loss = np.mean(batch_train_loss)\n","    epoch_train_loss.append(train_loss)\n","\n","    # Validation phase\n","    transformer.eval()  # Set model to evaluation mode\n","\n","    batch_val_loss = []\n","    with torch.no_grad():  # Disable gradient calculation during validation\n","        for batch in val_dataloader:\n","\n","            # Unpack the batch into x and y tensors\n","            x_batch, y_batch = batch\n","\n","            output = transformer(x_batch, mask=True)\n","\n","            output_tensor = output.view(-1, output.size(2))\n","            y_tensor = y_batch.view(-1)\n","\n","            loss = criterion(output_tensor, y_tensor).item()\n","            batch_val_loss.append(loss)\n","\n","    # Compute val loss for the epoch\n","    val_loss = np.mean(batch_val_loss)\n","    epoch_val_loss.append(val_loss)\n","\n","    # Check if validation loss improved\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model_state = transformer.state_dict()\n","        epochs_without_improvement = 0\n","    else:\n","        epochs_without_improvement += 1\n","\n","    # Print epoch results\n","    print(f'Epoch {epoch+1}: Training Loss: {epoch_train_loss[-1]}, Validation Loss: {epoch_val_loss[-1]}')\n","\n","    # Check for early stopping\n","    if epochs_without_improvement >= patience:\n","        print(f'Early stopping after {epoch+1} epochs.')\n","        break\n","\n","\n","# Use the best model state\n","if best_model_state is not None:\n","    transformer.load_state_dict(best_model_state)\n","    torch.save(transformer.state_dict(), 'best_model.pth')\n"],"metadata":{"id":"rzwPBZh92mwx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712566482593,"user_tz":-60,"elapsed":3096,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"19803bd0-70af-43dd-a563-3c350506c431"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["START_EPOCH\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 2/10 [00:00<00:02,  3.90it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Training Loss: 8560.75, Validation Loss: 8560.369140625\n","START_EPOCH\n","Epoch 2: Training Loss: 8560.3896484375, Validation Loss: 8559.6171875\n","START_EPOCH\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|████      | 4/10 [00:00<00:01,  5.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 3: Training Loss: 8559.7041015625, Validation Loss: 8558.2216796875\n","START_EPOCH\n","Epoch 4: Training Loss: 8558.4306640625, Validation Loss: 8556.2451171875\n","START_EPOCH\n"]},{"output_type":"stream","name":"stderr","text":[" 60%|██████    | 6/10 [00:01<00:00,  6.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 5: Training Loss: 8556.544921875, Validation Loss: 8553.703125\n","START_EPOCH\n","Epoch 6: Training Loss: 8554.1865234375, Validation Loss: 8550.1708984375\n","START_EPOCH\n"]},{"output_type":"stream","name":"stderr","text":[" 80%|████████  | 8/10 [00:01<00:00,  6.52it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 7: Training Loss: 8550.9228515625, Validation Loss: 8545.2568359375\n","START_EPOCH\n","Epoch 8: Training Loss: 8546.462890625, Validation Loss: 8537.5595703125\n","START_EPOCH\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:01<00:00,  5.91it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 9: Training Loss: 8539.619140625, Validation Loss: 8525.1669921875\n","START_EPOCH\n","Epoch 10: Training Loss: 8528.0302734375, Validation Loss: 8508.24609375\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# Plot loss over epochs\n","epochs = np.array(range(1, epoch+2))\n","\n","plt.plot(epochs, epoch_train_loss, label='Training Loss')\n","plt.plot(epochs, epoch_val_loss, label='Validation Loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"id":"bh-PTGSpRExj","executionInfo":{"status":"ok","timestamp":1712524018229,"user_tz":-60,"elapsed":749,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"c0c99d2e-3597-4856-e261-b0ca8946eaa6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAkQAAAHHCAYAAABeLEexAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACB0UlEQVR4nO3dd1xV9R/H8ddlXfaWlQiIG3FbqbnSFDQVs6GZoZmauU1LM82RmiOztNR+laOclaPcSo7cE9xbcOJAWYKMy/n9ceHqTU1U4AD383w8zqNzzj333M8Bgrff8/2er0ZRFAUhhBBCCBNmpnYBQgghhBBqk0AkhBBCCJMngUgIIYQQJk8CkRBCCCFMngQiIYQQQpg8CURCCCGEMHkSiIQQQghh8iQQCSGEEMLkSSASQgghhMmTQCREIde5c2f8/f2f6r0jR45Eo9HkbUGFTHR0NBqNhjlz5hT4Z2s0GkaOHGnYnjNnDhqNhujo6Me+19/fn86dO+dpPc/ysyKEqZNAJMRT0mg0uVo2b96sdqkmr2/fvmg0Gs6cOfPIY4YNG4ZGo+HQoUMFWNmTu3LlCiNHjiQyMlLtUgxyQunkyZPVLkWIp2ahdgFCFFW//PKL0fa8efPYsGHDA/srVqz4TJ/zv//9j6ysrKd672effcaQIUOe6fOLg44dOzJt2jQWLFjAiBEjHnrMwoULCQ4OpkqVKk/9OZ06daJ9+/ZotdqnPsfjXLlyhVGjRuHv70+1atWMXnuWnxUhTJ0EIiGe0jvvvGO0vWvXLjZs2PDA/n9LSUnB1tY2159jaWn5VPUBWFhYYGEh/5u/8MILlClThoULFz40EO3cuZPz58/z5ZdfPtPnmJubY25u/kzneBbP8rMihKmTW2ZC5KNGjRpRuXJl9u/fT4MGDbC1teXTTz8FYMWKFbRs2RIfHx+0Wi2BgYGMGTMGnU5ndI5/9wu5//bEDz/8QGBgIFqtltq1a7N3716j9z6sD5FGo6F3794sX76cypUro9VqCQoKYu3atQ/Uv3nzZmrVqoW1tTWBgYHMmjUr1/2S/vnnH9544w1KlSqFVqvF19eXAQMGkJqa+sD12dvbc/nyZcLCwrC3t6dEiRIMGjToga9FfHw8nTt3xsnJCWdnZ8LDw4mPj39sLaBvJTpx4gQHDhx44LUFCxag0Wjo0KED6enpjBgxgpo1a+Lk5ISdnR3169dn06ZNj/2Mh/UhUhSFL774gpIlS2Jra0vjxo05evToA++9desWgwYNIjg4GHt7exwdHQkNDSUqKspwzObNm6lduzYAXbp0MdyWzek/9bA+RHfu3OGjjz7C19cXrVZL+fLlmTx5MoqiGB33JD8XT+v69et07doVT09PrK2tqVq1KnPnzn3guEWLFlGzZk0cHBxwdHQkODiYb775xvB6RkYGo0aNomzZslhbW+Pm5sZLL73Ehg0b8qxWYXrkn45C5LO4uDhCQ0Np374977zzDp6enoD+j6e9vT0DBw7E3t6ev//+mxEjRpCYmMikSZMee94FCxaQlJREjx490Gg0TJw4kddee41z5849tqVg27ZtLF26lA8//BAHBwe+/fZb2rVrx4ULF3BzcwPg4MGDhISE4O3tzahRo9DpdIwePZoSJUrk6rp/++03UlJS6NmzJ25ubuzZs4dp06Zx6dIlfvvtN6NjdTodzZs354UXXmDy5Mls3LiRr776isDAQHr27Anog0WbNm3Ytm0bH3zwARUrVmTZsmWEh4fnqp6OHTsyatQoFixYQI0aNYw+e8mSJdSvX59SpUpx8+ZNfvzxRzp06EC3bt1ISkrip59+onnz5uzZs+eB21SPM2LECL744gtatGhBixYtOHDgAM2aNSM9Pd3ouHPnzrF8+XLeeOMNAgICuHbtGrNmzaJhw4YcO3YMHx8fKlasyOjRoxkxYgTdu3enfv36ANStW/ehn60oCq1bt2bTpk107dqVatWqsW7dOgYPHszly5f5+uuvjY7Pzc/F00pNTaVRo0acOXOG3r17ExAQwG+//Ubnzp2Jj4+nX79+AGzYsIEOHTrQpEkTJkyYAMDx48fZvn274ZiRI0cyfvx43n//fZ5//nkSExPZt28fBw4c4JVXXnmmOoUJU4QQeaJXr17Kv/+XatiwoQIoM2fOfOD4lJSUB/b16NFDsbW1Ve7evWvYFx4ervj5+Rm2z58/rwCKm5ubcuvWLcP+FStWKIDy119/GfZ9/vnnD9QEKFZWVsqZM2cM+6KiohRAmTZtmmFfq1atFFtbW+Xy5cuGfadPn1YsLCweOOfDPOz6xo8fr2g0GiUmJsbo+gBl9OjRRsdWr15dqVmzpmF7+fLlCqBMnDjRsC8zM1OpX7++AiizZ89+bE21a9dWSpYsqeh0OsO+tWvXKoAya9YswznT0tKM3nf79m3F09NTee+994z2A8rnn39u2J49e7YCKOfPn1cURVGuX7+uWFlZKS1btlSysrIMx3366acKoISHhxv23b1716guRdF/r7VardHXZu/evY+83n//rOR8zb744guj415//XVFo9EY/Qzk9ufiYXJ+JidNmvTIY6ZOnaoAyq+//mrYl56ertSpU0ext7dXEhMTFUVRlH79+imOjo5KZmbmI89VtWpVpWXLlv9ZkxBPSm6ZCZHPtFotXbp0eWC/jY2NYT0pKYmbN29Sv359UlJSOHHixGPP+9Zbb+Hi4mLYzmktOHfu3GPf27RpUwIDAw3bVapUwdHR0fBenU7Hxo0bCQsLw8fHx3BcmTJlCA0Nfez5wfj67ty5w82bN6lbty6KonDw4MEHjv/ggw+MtuvXr290LatXr8bCwsLQYgT6Pjt9+vTJVT2g7/d16dIltm7dati3YMECrKyseOONNwzntLKyAiArK4tbt26RmZlJrVq1Hnq77b9s3LiR9PR0+vTpY3SbsX///g8cq9VqMTPT/0rW6XTExcVhb29P+fLln/hzc6xevRpzc3P69u1rtP+jjz5CURTWrFljtP9xPxfPYvXq1Xh5edGhQwfDPktLS/r27UtycjJbtmwBwNnZmTt37vzn7S9nZ2eOHj3K6dOnn7kuIXJIIBIinz333HOGP7D3O3r0KG3btsXJyQlHR0dKlChh6JCdkJDw2POWKlXKaDsnHN2+ffuJ35vz/pz3Xr9+ndTUVMqUKfPAcQ/b9zAXLlygc+fOuLq6GvoFNWzYEHjw+qytrR+4FXd/PQAxMTF4e3tjb29vdFz58uVzVQ9A+/btMTc3Z8GCBQDcvXuXZcuWERoaahQu586dS5UqVQz9U0qUKMGqVaty9X25X0xMDABly5Y12l+iRAmjzwN9+Pr6668pW7YsWq0Wd3d3SpQowaFDh574c+//fB8fHxwcHIz254x8zKkvx+N+Lp5FTEwMZcuWNYS+R9Xy4YcfUq5cOUJDQylZsiTvvffeA/2YRo8eTXx8POXKlSM4OJjBgwcX+scliMJPApEQ+ez+lpIc8fHxNGzYkKioKEaPHs1ff/3Fhg0bDH0mcjN0+lGjmZR/dZbN6/fmhk6n45VXXmHVqlV88sknLF++nA0bNhg6//77+gpqZJaHhwevvPIKf/zxBxkZGfz1118kJSXRsWNHwzG//vornTt3JjAwkJ9++om1a9eyYcMGXn755Xwd0j5u3DgGDhxIgwYN+PXXX1m3bh0bNmwgKCiowIbS5/fPRW54eHgQGRnJn3/+aej/FBoaatRXrEGDBpw9e5aff/6ZypUr8+OPP1KjRg1+/PHHAqtTFD/SqVoIFWzevJm4uDiWLl1KgwYNDPvPnz+vYlX3eHh4YG1t/dAHGf7Xww1zHD58mFOnTjF37lzeffddw/5nGQXk5+dHREQEycnJRq1EJ0+efKLzdOzYkbVr17JmzRoWLFiAo6MjrVq1Mrz++++/U7p0aZYuXWp0m+vzzz9/qpoBTp8+TenSpQ37b9y48UCry++//07jxo356aefjPbHx8fj7u5u2H6SJ4/7+fmxceNGkpKSjFqJcm7J5tRXEPz8/Dh06BBZWVlGrUQPq8XKyopWrVrRqlUrsrKy+PDDD5k1axbDhw83tFC6urrSpUsXunTpQnJyMg0aNGDkyJG8//77BXZNoniRFiIhVJDzL/H7/+Wdnp7O999/r1ZJRszNzWnatCnLly/nypUrhv1nzpx5oN/Jo94PxtenKIrR0Okn1aJFCzIzM5kxY4Zhn06nY9q0aU90nrCwMGxtbfn+++9Zs2YNr732GtbW1v9Z++7du9m5c+cT19y0aVMsLS2ZNm2a0fmmTp36wLHm5uYPtMT89ttvXL582WifnZ0dQK4eN9CiRQt0Oh3Tp0832v/111+j0Why3R8sL7Ro0YLY2FgWL15s2JeZmcm0adOwt7c33E6Ni4szep+ZmZnhYZlpaWkPPcbe3p4yZcoYXhfiaUgLkRAqqFu3Li4uLoSHhxumlfjll18K9NbE44wcOZL169dTr149evbsafjDWrly5cdOG1GhQgUCAwMZNGgQly9fxtHRkT/++OOZ+qK0atWKevXqMWTIEKKjo6lUqRJLly594v419vb2hIWFGfoR3X+7DODVV19l6dKltG3blpYtW3L+/HlmzpxJpUqVSE5OfqLPynme0vjx43n11Vdp0aIFBw8eZM2aNUatPjmfO3r0aLp06ULdunU5fPgw8+fPN2pZAggMDMTZ2ZmZM2fi4OCAnZ0dL7zwAgEBAQ98fqtWrWjcuDHDhg0jOjqaqlWrsn79elasWEH//v2NOlDnhYiICO7evfvA/rCwMLp3786sWbPo3Lkz+/fvx9/fn99//53t27czdepUQwvW+++/z61bt3j55ZcpWbIkMTExTJs2jWrVqhn6G1WqVIlGjRpRs2ZNXF1d2bdvH7///ju9e/fO0+sRJkadwW1CFD+PGnYfFBT00OO3b9+uvPjii4qNjY3i4+OjfPzxx8q6desUQNm0aZPhuEcNu3/YEGf+NQz8UcPue/Xq9cB7/fz8jIaBK4qiREREKNWrV1esrKyUwMBA5ccff1Q++ugjxdra+hFfhXuOHTumNG3aVLG3t1fc3d2Vbt26GYZx3z9kPDw8XLGzs3vg/Q+rPS4uTunUqZPi6OioODk5KZ06dVIOHjyY62H3OVatWqUAire39wND3bOyspRx48Ypfn5+ilarVapXr66sXLnyge+Dojx+2L2iKIpOp1NGjRqleHt7KzY2NkqjRo2UI0eOPPD1vnv3rvLRRx8ZjqtXr56yc+dOpWHDhkrDhg2NPnfFihVKpUqVDI9AyLn2h9WYlJSkDBgwQPHx8VEsLS2VsmXLKpMmTTJ6DEDOteT25+Lfcn4mH7X88ssviqIoyrVr15QuXboo7u7uipWVlRIcHPzA9+33339XmjVrpnh4eChWVlZKqVKllB49eihXr141HPPFF18ozz//vOLs7KzY2NgoFSpUUMaOHaukp6f/Z51C/BeNohSif5IKIQq9sLAwGfIshCh2pA+REOKR/j3NxunTp1m9ejWNGjVSpyAhhMgn0kIkhHgkb29vOnfuTOnSpYmJiWHGjBmkpaVx8ODBB56tI4QQRZl0qhZCPFJISAgLFy4kNjYWrVZLnTp1GDdunIQhIUSxIy1EQgghhDB50odICCGEECZPApEQQgghTJ70IcqlrKwsrly5goODwxM9Ol8IIYQQ6lEUhaSkJHx8fB6YXPh+Eohy6cqVK/j6+qpdhhBCCCGewsWLFylZsuQjX5dAlEs5j5W/ePEijo6OKlcjhBBCiNxITEzE19fXaILjh5FAlEs5t8kcHR0lEAkhhBBFzOO6u0inaiGEEEKYPAlEQgghhDB5EoiEEEIIYfKkD5EQQogCodPpyMjIULsMUcxYWlpibm7+zOeRQCSEECJfKYpCbGws8fHxapciiilnZ2e8vLye6TmBEoiEEELkq5ww5OHhga2trTzcVuQZRVFISUnh+vXrAHh7ez/1uSQQCSGEyDc6nc4Qhtzc3NQuRxRDNjY2AFy/fh0PD4+nvn0mnaqFEELkm5w+Q7a2tipXIoqznJ+vZ+mjJoFICCFEvpPbZCI/5cXPlwQiIYQQQpg8CURCCCFEAfH392fq1Km5Pn7z5s1oNBoZoVcAJBAJIYQQ/6LRaP5zGTly5FOdd+/evXTv3j3Xx9etW5erV6/i5OT0VJ+XWxK8ZJSZ6mLi7qC1MMfGyhxbK3MszSWjCiGE2q5evWpYX7x4MSNGjODkyZOGffb29oZ1RVHQ6XRYWDz+T2qJEiWeqA4rKyu8vLye6D3i6chfX5WFfvMPL46PoOqo9ZQdtoayw1ZTZeQ6XhwXwcuTN9Py2394Y+YO3v15Dx/8sp+BiyP5bPlhxq0+ztcbTjFry1l+2RnN7/svsfrwVTadvM7uc3EcvpTAmevJXIlPJT4lnbRMHYqiqH25QghRJHh5eRkWJycnNBqNYfvEiRM4ODiwZs0aatasiVarZdu2bZw9e5Y2bdrg6emJvb09tWvXZuPGjUbn/fctM41Gw48//kjbtm2xtbWlbNmy/Pnnn4bX/91yM2fOHJydnVm3bh0VK1bE3t6ekJAQowCXmZlJ3759cXZ2xs3NjU8++YTw8HDCwsKe+utx+/Zt3n33XVxcXLC1tSU0NJTTp08bXo+JiaFVq1a4uLhgZ2dHUFAQq1evNry3Y8eOlChRAhsbG8qWLcvs2bOfupb8omoLkU6nY+TIkfz666/Exsbi4+ND586d+eyzzww9xjt37szcuXON3te8eXPWrl1rtG/VqlWMHj2aQ4cOYW1tTcOGDVm+fLnh9QsXLtCzZ082bdqEvb094eHhjB8/PleJPr8oioKFmQZzMw26LH1YydApZOgySbybmeefZ26mwdbSHFutObZWFthY6lulclqnbK0s9OuG/Rb/el1/TM66jZUFtpb617UWZjKKRAiRK4qikJqhK/DPtbE0z9PfU0OGDGHy5MmULl0aFxcXLl68SIsWLRg7dixarZZ58+bRqlUrTp48SalSpR55nlGjRjFx4kQmTZrEtGnT6NixIzExMbi6uj70+JSUFCZPnswvv/yCmZkZ77zzDoMGDWL+/PkATJgwgfnz5zN79mwqVqzIN998w/Lly2ncuPFTX2vnzp05ffo0f/75J46OjnzyySe0aNGCY8eOYWlpSa9evUhPT2fr1q3Y2dlx7NgxQyva8OHDOXbsGGvWrMHd3Z0zZ86Qmpr61LXkF1UD0YQJE5gxYwZz584lKCiIffv20aVLF5ycnOjbt6/huJCQEKM0qdVqjc7zxx9/0K1bN8aNG8fLL79MZmYmR44cMbyu0+lo2bIlXl5e7Nixg6tXr/Luu+9iaWnJuHHj8v9CH0Gj0XCoxAgUjRmKbQkybdxJt3bjrtaNu1ZuJFu4kGzhQqK5C/EaZ+7ozEhJ15GSriM1Q0dKeqZ+O01HSoaO1Ozt1OxjUtIzSc3QkaHThy1dlkJSWiZJaZlAWp5ei5kG7LUWuNlrcbWzwtXOCnd7q+x17X3rVrjZ6Y+xspAGSiFMUWqGjkoj1hX45x4b3Rxbq7z7szd69GheeeUVw7arqytVq1Y1bI8ZM4Zly5bx559/0rt370eep3PnznTo0AGAcePG8e2337Jnzx5CQkIeenxGRgYzZ84kMDAQgN69ezN69GjD69OmTWPo0KG0bdsWgOnTpxtaa55GThDavn07devWBWD+/Pn4+vqyfPly3njjDS5cuEC7du0IDg4GoHTp0ob3X7hwgerVq1OrVi1A30pWGKkaiHbs2EGbNm1o2bIloP8iLVy4kD179hgdp9VqH3kPNTMzk379+jFp0iS6du1q2F+pUiXD+vr16zl27BgbN27E09OTatWqMWbMGD755BNGjhyJlZVVPlxdLmTp4MZJNChoAKvsxf5Rx2udwL4E2Hlk/7cEON+3bucB9l76dSt7yP6XUIYu676glHlfoLoXonJev5OeeV+g0pGaYfx6Ss7r2e9Pz8zSX4oCiXf1LVvnb97J1eU7WFvglhOS7LWGdX2Yuhes3LLDlNbi2SfvE0KIvJLzBz5HcnIyI0eOZNWqVVy9epXMzExSU1O5cOHCf56nSpUqhnU7OzscHR0NU1E8jK2trSEMgX66ipzjExISuHbtGs8//7zhdXNzc2rWrElWVtYTXV+O48ePY2FhwQsvvGDY5+bmRvny5Tl+/DgAffv2pWfPnqxfv56mTZvSrl07w3X17NmTdu3aceDAAZo1a0ZYWJghWBUmqgaiunXr8sMPP3Dq1CnKlStHVFQU27ZtY8qUKUbHbd68GQ8PD1xcXHj55Zf54osvDI+AP3DgAJcvX8bMzIzq1asTGxtLtWrVmDRpEpUrVwZg586dBAcH4+npaThn8+bN6dmzJ0ePHqV69eoP1JaWlkZa2r1WlMTExHz4Cmjgg38g+TrcuaFfctbv33fnBmRlQlqCfok78/hTW9gYwpOlXQmc7EvgZOehD0s5ocole9vaGcyerrUmU5dFaoY+LCXezeTWnXTiktOIu5POrezlZnLafevp3E5J17dW3c0k6W4m0XEpufosB60Frvb3Wpnc7KxwtbfCzRCajEOVtaUEKCEKIxtLc46Nbq7K5+YlOzs7o+1BgwaxYcMGJk+eTJkyZbCxseH1118nPT39P89jaWlptK3RaP4zvDzseLX7iL7//vs0b96cVatWsX79esaPH89XX31Fnz59CA0NJSYmhtWrV7NhwwaaNGlCr169mDx5sqo1/5uqgWjIkCEkJiZSoUIFzM3N0el0jB07lo4dOxqOCQkJ4bXXXiMgIICzZ8/y6aefEhoays6dOzE3N+fcuXMAjBw5kilTpuDv789XX31Fo0aNOHXqFK6ursTGxhqFIcCwHRsb+9Daxo8fz6hRo/LpyrOZmYFX8OOPy8qCu/EPBqVHrWekQGYqxF/QL4+twyK7hck9u5XJ41/r2S1Q9h5g6w7m935sLMzNcDA3w8HaEg/H3F12VpZC4t0M4u6kE5eczq072QEqOV2/7072vuzt23fSybzvdl9MLgOUvdbiobfv3O5rdXKz0xpClQQoIQqGRqPJ01tXhcX27dvp3Lmz4VZVcnIy0dHRBVqDk5MTnp6e7N27lwYNGgD6biMHDhygWrVqT3XOihUrkpmZye7duw0tO3FxcZw8edLoboyvry8ffPABH3zwAUOHDuV///sfffr0AfSj68LDwwkPD6d+/foMHjxYAtH9lixZwvz581mwYAFBQUFERkbSv39/fHx8CA8PB6B9+/aG44ODg6lSpQqBgYFs3ryZJk2aGFL0sGHDaNeuHQCzZ8+mZMmS/Pbbb/To0eOpahs6dCgDBw40bCcmJuLr6/u0l/pszMzA1lW/lCj/+OPTkv8jNF2HOzfvrd9N0Lc+JV3VL7lh43ovKN0fmBx9wL0cuJcF60c/M8PMTIOzrRXOtlYE5mIEqqIoJKZmEpcdnPQh6r9bojKzFJLTMklOy+TCrdwFKDsrc1ztrShhr8XfzY4Adzv83e/9115b/H6BCyHyTtmyZVm6dCmtWrVCo9EwfPjwp75N9Sz69OnD+PHjKVOmDBUqVGDatGncvn07Vx3KDx8+jIODg2Fbo9FQtWpV2rRpQ7du3Zg1axYODg4MGTKE5557jjZt2gDQv39/QkNDKVeuHLdv32bTpk1UrFgRgBEjRlCzZk2CgoJIS0tj5cqVhtcKE1V/ww8ePJghQ4YYQk9wcDAxMTGMHz/eEIj+rXTp0oZe6k2aNMHb2xsw7jOk1WopXbq04b6tl5fXA/2Srl27ZnjtYbRa7QOdt4sMrb1+cQ14/LGZ6dmB6V9B6WHrKTdByYLUW/rlxolHn9feC0qUA/fy+hDnXla/7uBl6NuUWxqNBidbS5xsLSmd2wB1N5O47ICUE5oeDFD6lqhbd9LJ0CncSddx51YqF2+lcuBC/APnLeGgJcDNDn93WwLc7Qlwt8Xf3Q5/NztpXRJCMGXKFN577z3q1q2Lu7s7n3zyST51t/hvn3zyCbGxsbz77ruYm5vTvXt3mjdvnqtZ4HNalXKYm5uTmZnJ7Nmz6devH6+++irp6ek0aNCA1atXG27f6XQ6evXqxaVLl3B0dCQkJISvv/4a0D9LaejQoURHR2NjY0P9+vVZtGhR3l/4M9IoKt54dHNz44svvqBnz56GfePHj2f27NmcOnXqoe+5dOkSpUqVYvny5bRu3ZrExEQ8PDz47rvvDJ2qMzIyKFmyJGPGjKF79+6sWbOGV199latXr+Lh4QHADz/8wODBg7l+/Xqugk9iYiJOTk4kJCTg6JjLe0PFTZYOUm8/IjTd0N+eu3n6v1uatI73wlFOYHIvBy7+RrfiCpKi6G/H5dy+i01IIzruDudv6pfom3eIu/PffQB8nKz14cjdjtLZIcnf3Y5SrrYymk6YtLt373L+/HkCAgKwtrZWuxyTlJWVRcWKFXnzzTcZM2aM2uXki//6Ocvt329VW4hatWrF2LFjKVWqFEFBQRw8eNCQsEF//3XUqFG0a9cOLy8vzp49y8cff0yZMmVo3lzfIc/R0ZEPPviAzz//HF9fX/z8/Jg0aRIAb7zxBgDNmjWjUqVKdOrUiYkTJxIbG8tnn31Gr169im4rkBrMzLP7FrkDlR593N0EfTC6eQpunLz339vnIS0RLu/XL/cztwLXQH1YKlE+OyiV1S9Wdg//nDyi0WhwtLbE0dqSAPeHf1ZCagbRN+8YglL0zXuBKfFuJlcS7nIl4S47zsYZvc9MAyVdbO8LSraG23DPOdtgIU8mF0LksZiYGNavX0/Dhg1JS0tj+vTpnD9/nrffflvt0go1VVuIkpKSGD58OMuWLeP69ev4+PjQoUMHRowYgZWVFampqYSFhXHw4EHi4+Px8fGhWbNmjBkzxqiTdEZGBkOHDuWXX34hNTWVF154galTpxIUFGQ4JiYmhp49e7J582bs7OwIDw/nyy+/zPWDGaWFKA9kpsGtc9kh6TTcPHlvPfM/HtLlVCq7NSl7yQlMdm4FV/sjKIrC7ZQMzt9M5vzNFKOgFB13h5T0Rz98ztJcg6+rLQEP6a/k7WiNmZk86FIUfdJCVPAuXrxI+/btOXLkCIqiULlyZb788ssHbocVJ3nRQqRqICpKJBDlo6wsSLwEN07pQ9LNU/fWU+Ie/T6b7E7mRkGpHDj5PvVjBPKSoijcSErjXE6LUtwdzt/QB6XouBTDM5weRmthln3b7b7+StnBqYSDVp4KLooMCUSiIBT5W2ZCAPrw4lxKv5RtavzanTh9QLp50jgwxV/Qd+y+sFO/3M/CBtzLPNih2y0QLAruFqlGo8HD0RoPR2teLG3cmpWVpXAlIZXomymcj7t3Cy765h0u3EohLTOLk9eSOHktCbhm9F47K/OH9lcq7W6Hi51KDxkVQogiTgKRKNzs3MCuDvjVMd6fngJxp/W3226cvBeYbp3V336LPaxf7qcx03fe/neH7hLl/vMxAfnBzExDSRdbSrrY8lJZd6PXMnVZXLqdahSUcm7BXb6dyp10HUevJHL0yoOjV5xsLPW33txsCSxhT7VSzlQv5SKPDBBCiMeQ35KiaLKyBe+q+uV+ukyIj7nXmfv+jt1pifo+TLfOwak1xu+z97rXodujIpSqCyUqqHLrzcLczNACxL8eO5WWqePirRRDf6Wc23HRcXe4mnCXhNQMoi7GE3Ux3vAeMw1U9Haklp8LNf1dqe3vgreTTcFelBBCFHLShyiXpA9REacokHzNeNRbTmB61GMCbN3Arx741wf/elCiYqHom/Qoqek6ff+k7P5KJ2OT2Bd9m8vxD3ZYf87Zhpp+LtTyd6GmnwsVvBwxl07cIh9IHyJREKRTdQGSQFSM3U2Am2fujXq7GgkX9+inQLmfjas+GPnXB/+XCn1AyhGbcJd9MbfYF32bfTG3OHYlkax//V9vr7Wgeilnavm5UsvfhWq+ztjJbTaRByQQiYIggagASSAyMZnpcOUgRP8D0dvg4u6HBCSX+1qQXgKPSkUiIN1JyyTyYrwhIB28EE9yWqbRMeZmGip5OxpakWr5ueLlJH/MxJOTQCQKggSiAiSByMRlputbjnIC0oXdkHHH+BhDQHopOyAFFYmApMtSOBGbyP6Y2+yNvs3+6FtcSbj7wHElXWwM/ZBq+blQztNBbrOJxzL1QNSoUSOqVavG1KlTAfD396d///7079//ke/RaDQsW7aMsLCwZ/rsvDpPUSDD7oUoKBZW4Pu8fqn/Eegy4ErkfQFpl35akxMr9QuAtbNxQPKsXCgDkrmZhiAfJ4J8nHi3jj8AV+JT2Rdzm33R+lttJ2ITuXQ7lUu3U1keeQUAB2sLapRyyQ5J+ttsxXEGc2GaWrVqRUZGBmvXrn3gtX/++YcGDRoQFRVFlSpVnui8e/fuxc4ub5++P3LkSJYvX05kZKTR/qtXr+Li4pKnn/Vvc+bMoX///sTHx+fr5xQE+e0lxNMwtwTf2vql/kB9QLoaZRyQ7sbDyVX6BbIDUt1/BaTCOSmsj7MNrZ1taF3VB4CkuxkP3GZLupvJllM32HLqBgAWZhqCfBypmd0PqZafCx6OptciIIqHrl270q5dOy5dukTJkiWNXps9eza1atV64jAEUKJELmaoziOPmrxcPFzh++eqEEWRuSWUrAUvDYB3/oBPYuD9v6HpKCjzCljZZwek1bDuU5jVACYGwIL2sGO6vrUp69HTfKjNwdqS+mVLMOCVcsx//0UOfd6MlX1eYmSrSrSs4o2XozWZWQpRlxL4eft5Ppx/gOfHRdBg4iYGLo5k/u4YTl1LIuvfvbmFKKReffVVSpQowZw5c4z2Jycn89tvv9G1a1fi4uLo0KEDzz33HLa2tgQHB7Nw4cL/PK+/v7/h9hnA6dOnadCgAdbW1lSqVIkNGzY88J5PPvmEcuXKYWtrS+nSpRk+fDgZGRmAvoVm1KhRREVFodFo0Gg0hpo1Gg3Lly83nOfw4cO8/PLL2NjY4ObmRvfu3UlOTja83rlzZ8LCwpg8eTLe3t64ubnRq1cvw2c9jQsXLtCmTRvs7e1xdHTkzTff5Nq1ew+bjYqKonHjxjg4OODo6EjNmjXZt28foJ9yq1WrVri4uGBnZ0dQUBCrV69+6loeR1qIhMgP5hZQsqZ+eam//vlIsVH61qPobRCzUz+67dSae89E0jpltyBl32bzqlJoW5AszM2o/JwTlZ9zonO9ABRF4XJ8anY/JP1ttpPXkrhwK4ULt1JYevAyAI7WFtkdtV2p6ae/zWZtWTivUeQjRXlwkEJBsLSFXE57Y2FhwbvvvsucOXMYNmyYYbqc3377DZ1OR4cOHUhOTqZmzZp88sknODo6smrVKjp16kRgYCDPP//8Yz8jKyuL1157DU9PT3bv3k1CQsJD+xY5ODgwZ84cfHx8OHz4MN26dcPBwYGPP/6Yt956iyNHjrB27Vo2btwIgJPTgw+avXPnDs2bN6dOnTrs3buX69ev8/7779O7d2+j0Ldp0ya8vb3ZtGkTZ86c4a233qJatWp069YtV1+3f19fThjasmULmZmZ9OrVi7feeovNmzcD0LFjR6pXr86MGTMwNzcnMjISS0tLAHr16kV6ejpbt27Fzs6OY8eOYW9v/8R15JYEIiEKgrkFPFdTv9Trlx2QDt0LSBd2Qtq/A5KjPiD53ReQzAvn/7Iazb0nb7ep9hwAiXczOHghnv3Rt9gbfZvIi/Ek3s1k08kbbDqpv81maa7vv1TL8EwkV0o4FNz0KkIlGSkwzqfgP/fTK2CV+/477733HpMmTWLLli00atQI0N8ua9euHU5OTjg5OTFo0CDD8X369GHdunUsWbIkV4Fo48aNnDhxgnXr1uHjo/96jBs3jtDQUKPjPvvsM8O6v78/gwYNYtGiRXz88cfY2Nhgb2+PhYXFf94iW7BgAXfv3mXevHmGPkzTp0+nVatWTJgwwTBhuouLC9OnT8fc3JwKFSrQsmVLIiIinioQRUREcPjwYc6fP4+vry8A8+bNIygoiL1791K7dm0uXLjA4MGDqVChAgBly5Y1vP/ChQu0a9eO4OBgAEqXLv3ENTyJwvnbVYjiztwCnquhX+r1vReQYrZntyDt0D9Z+9Ra/QL6gFSqTnYfpHrgVbXQBiQAR2tLGpYrQcNy+j4TGbosjl9NNPRD2hd9m+tJaURejCfyYjw/bjsPgL+brVE/pMAS9pjJaDahggoVKlC3bl1+/vlnGjVqxJkzZ/jnn38YPXo0ADqdjnHjxrFkyRIuX75Meno6aWlp2Nra5ur8x48fx9fX1xCGAOrUqfPAcYsXL+bbb7/l7NmzJCcnk5mZ+cSjnY8fP07VqlWNOnTXq1ePrKwsTp48aQhEQUFBmJvfa7X19vbm8OHDD5wvt5/p6+trCEMAlSpVwtnZmePHj1O7dm0GDhzI+++/zy+//ELTpk154403CAwMBKBv37707NmT9evX07RpU9q1a/dU/bZyq/D+NhXClNwfkOr20fcnMrQgbc8OSAlwep1+AbBy0M/x5v8S+L2kn8akEAckS3MzqpR0pkpJZ957SX+b7dLt1HsPjYy+zanrSUTHpRAdl8IfBy4B4GJrSZOKnrSs4k29QHesLKTrY5FnaatvrVHjc59Q165d6dOnD9999x2zZ88mMDCQhg0bAjBp0iS++eYbpk6dSnBwMHZ2dvTv35/09PQ8K3nnzp107NiRUaNG0bx5c5ycnFi0aBFfffVVnn3G/XJuV+XQaDRkZWXly2eBfoTc22+/zapVq1izZg2ff/45ixYtom3btrz//vs0b96cVatWsX79esaPH89XX31Fnz598qWWwvvbUwhTZmYOPtX1iyEgHc5uPdquX+4mwOn1+gX0AanUi9ktSPULfUDSaDT4utri62pL2+r6UTwJqRkcuHCb/dH6vkhRl+K5nZLB7/sv8fv+SzjZWNI8yJOWVXyoG+iGpbmEoyJJo3miW1dqevPNN+nXrx8LFixg3rx59OzZ09CfaPv27bRp04Z33nkH0PeZOXXqFJUqVcrVuStWrMjFixe5evUq3t7eAOzatcvomB07duDn58ewYcMM+2JiYoyOsbKyQqf770EZFStWZM6cOdy5c8fQSrR9+3bMzMwoX778f773aeVc38WLFw2tRMeOHSM+Pt7oa1SuXDnKlSvHgAED6NChA7Nnz6Zt27YA+Pr68sEHH/DBBx8wdOhQ/ve//0kgEsKkmZmDTzX9Ure3PiBdO3JfC9I2fUA6s0G/gD4gVWoNVTvo+yEVwmcg/ZuTjSWNy3vQuLwHoL/Ntj/mNqsPX2X14VhuJqexZN8lluy7hLOtJSFBXrSs4k2d0m5YSDgS+cDe3p633nqLoUOHkpiYSOfOnQ2vlS1blt9//50dO3bg4uLClClTuHbtWq4DUdOmTSlXrhzh4eFMmjSJxMREo+CT8xkXLlxg0aJF1K5dm1WrVrFs2TKjY/z9/Tl//jyRkZGULFkSBwcHtFrjvngdO3bk888/Jzw8nJEjR3Ljxg369OlDp06dDLfLnpZOp3vgGUharZamTZsSHBxMx44dmTp1KpmZmXz44Yc0bNiQWrVqkZqayuDBg3n99dcJCAjg0qVL7N27l3bt2gHQv39/QkNDKVeuHLdv32bTpk1UrFjxmWr9LxKIhCiKzMz1LUDeVaFOr+yAdPS+UWzb9cP8I+frF6dSUPUtfThyC1S7+lyzNDfjxdJuvFjajc9bBbHn/C1WHb7C2iOx3ExOZ9HeiyzaexEXW0tCKnvRMtiHF0u7SjgSeapr16789NNPtGjRwqi/z2effca5c+do3rw5tra2dO/enbCwMBISEnJ1XjMzM5YtW0bXrl15/vnn8ff359tvvyUkJMRwTOvWrRkwYAC9e/cmLS2Nli1bMnz4cEaOHGk4pl27dixdupTGjRsTHx/P7NmzjYIbgK2tLevWraNfv37Url0bW1tb2rVrx5QpU57pawP6RxFUr17daF9gYCBnzpxhxYoV9OnThwYNGmBmZkZISAjTpk0DwNzcnLi4ON59912uXbuGu7s7r732GqNGjQL0QatXr15cunQJR0dHQkJC+Prrr5+53keRqTtySabuEEVKVhZc3AVRC+Hocn0H7Rwln4dqHSCorX66kSJIl6Ww+3wcqw5dZe2RWOLu3Ouz4WpnRUhlL14N9ub5AAlHajP1qTtEwZC5zAqQBCJRZGWkwolV+nB09m9QsjtImmuhfKi+1ahME/3DJYugTF0Wu8/fYuWhq6w9cpXbKfceIudub2VoOXo+wFXmXlOBBCJRECQQFSAJRKJYSIqFQ0v04ej6sXv77UpA8Bv6cOSdf8Na81uGLotd57Jbjo7GEm8UjrS0CPaiZbA3tfwlHBUUCUSiIEggKkASiESxoij6Yf1Ri/QBKeXmvdc8K0PV9hD8Jjg8W2dLNWXosthxNo5Vh66w7ug1ElLvhSMPBy2hlb1oWcWHWn4u8pyjfCSBSBQECUQFSAKRKLZ0GXBmo77V6OQa0GX3x9GYQWATfX+j8i3A0kbdOp9BemYWO87eZNWhq6w7Gkvi3UzDa56OWkIre/NqFW9qlJJwlNckEImCIIGoAEkgEiYh5RYcXaYPR5f23tuvdYKgMP0ttVIv5no+qMIoPTOL7WdusvLQVdYfiyXpvnDk5WhNi2BvWlbxprqvs4SjPJDzh8rf3x8bm6IbqkXhlpqaSnR0tASigiCBSJicm2f0wejQYki4eG+/S4A+GFV9C1z8VSsvL6Rl6th2Wt9ytOHYNZLS7oUjH6d74aiar7PhYXziyeh0Ok6dOoWHhwdubm5qlyOKqbi4OK5fv065cuWMph4BCUR5TgKRMFlZWfoHP0Yt0g/hz7hz7zW/evr+RpXCwLpo/39xN0PHP6dvsurQFTYcu8ad9HtP/n3O2YaWVbxpEexN1ZJOEo6e0NWrV4mPj8fDwwNbW1v5+ok8oygKKSkpXL9+HWdnZ8MTv+8ngSiPSSASAki/A8f/0rccndsCZP/6sLCGCq/q+xuVbqx/cGQRdjdDx9ZTN1h1+Cob/xWOSrrY0DK75Sj4OQlHuaEoCrGxscTHx6tdiiimnJ2d8fLyeuj/jxKI8pgEIiH+JeHSvSH8N0/d22/vBVXe1N9W88zdFAaF2d0MHZtP6sNRxPFrpNwXjnxdbWgZ7MOrVbwJ8nGUcPQYOp2OjIyMxx8oxBOwtLR84DbZ/SQQ5TEJREI8gqLAlQMQuRCO/A6pt++95l0Vqr4Nwa+Dnbt6NeaR1HQdm09eZ+Xhq/x9/DqpGffCkZ+braHlqJK3hCMhCgsJRHlMApEQuZCZDqfX6cPR6XWQld1J2cwCyjbT9zcqFwIW2v8+TxGQkp7JphM3WHX4Cn+fuM7djCzDawHudrQM1vc5qujtIOFICBVJIMpjEoiEeEJ34vQtRlEL4crBe/utnaFyO6j2NjxXs0gP4c9xJy2TTSevs+rQVf4+cZ20zHvhqLS7HS2r6FuOKnjJ7w4hCpoEojwmgUiIZ3D9ePZTsRdD0tV7+93K6luNqrwFzr7q1ZeH7qRlEnHiOqsOXWHTyRuk3xeO6pVxY2hoRSo/56RihUKYFglEeUwCkRB5IEsH57fob6kd/wsyU7Nf0EBAfX1H7IqtQWuvapl5JeluBn+fuM7KQ1fZfPI6GTr9r9s21XwY1Kw8vq62KlcoRPEngSiPSSASIo+lJcGxFfpwFLPt3n5LO6jUWt9y5N8AzMzUqzEPXbyVwlfrT7I88goAVuZmdKrjR+/GZXCxs1K5OiGKLwlEeUwCkRD56HaM/nZa1EK4de7efseS+idiv9AT7EuoV18eOnI5gQlrT/DPaf2Eug7WFvRsFMh79QKwtizaz28SojCSQJTHJBAJUQAUBS7u0QejI0shLUG/39oJXh4Otd4r8g99zLH11A2+XHOCY1cTAf08agOblaNdjZKYyxxqQuQZCUR5TAKREAUs4y6cWgP/TIHYQ/p9XlWg5Vfg+7y6teWRrCyFFVGXmbzuFJfj9f2pyns68EloeRqX95Dh+kLkAQlEeUwCkRAqydLBvp/h7zFwN7vFqPo70HRUsXjYI+ifhv3LzhimbzpDQqr+Sc4vlnZlaGhFqvo6q1ucEEWcBKI8JoFICJUl34CNIyHyV/22tRM0GQE1uxSb22gJKRl8v+UMs7dHG4brt6zizcfNy+PnZqdydUIUTRKI8pgEIiEKiQu7YfVHEHtYv+1dFVpOgZK11K0rD12OT2XK+lMsPXgJRQELMw0dXyhFnyZlcbcv+k/5FqIgSSDKYxKIhChEdJnZt9G+uNfxusa70GQk2LmpWlpeOn41kQlrT7D55A0A7LUW9GhQmq71A7C1slC5OiGKBglEeUwCkRCFUPJ12PA5RC3Qb1s7Q9PPoUZ4sbmNBrDjzE3GrznB4cv68OfhoGXAK+V4o2ZJLMyLx3OahMgvuf37rer/STqdjuHDhxMQEICNjQ2BgYGMGTOG+zNa586d0Wg0RktISIjRefz9/R845ssvvzQ65tChQ9SvXx9ra2t8fX2ZOHFigVyjECIf2XtA2xnQZS14Voa78bByAPzYBC7vV7u6PFO3jDsretXj2w7V8XW14XpSGkOXHqb51K2sPxqL/LtWiGenapvrhAkTmDFjBnPnziUoKIh9+/bRpUsXnJyc6Nu3r+G4kJAQZs+ebdjWah+8hz569Gi6detm2HZwcDCsJyYm0qxZM5o2bcrMmTM5fPgw7733Hs7OznTv3j2frk4IUWD86kD3LbD3R9g0Vj+Z7P+aQM1waPI52LqqXeEzMzPT0LqqDyFBXszfHcO0v89w9sYduv+yn9r+LgwJrUhNPxe1yxSiyFI1EO3YsYM2bdrQsmVLQN/Ss3DhQvbs2WN0nFarxcvL6z/P5eDg8Mhj5s+fT3p6Oj///DNWVlYEBQURGRnJlClTJBAJUVyYW8CLH0BQW9gwAg4tgv1z9NODNB0J1d8tFtOAWFmY0aVeAO1qlmTWlrP8tO08e6Nv027GDkKCvBgcUp7AEsVjLjghCpKqvx3q1q1LREQEp06dAiAqKopt27YRGhpqdNzmzZvx8PCgfPny9OzZk7i4uAfO9eWXX+Lm5kb16tWZNGkSmZmZhtd27txJgwYNsLK6N19Q8+bNOXnyJLdv335obWlpaSQmJhotQogiwMETXpsFnVeDRxCk3oa/+sFPTeHyAbWryzOO1pYMbl6BzYMa0762L2YaWHs0lmZfb2XYssNcT7qrdolCFCmqBqIhQ4bQvn17KlSogKWlJdWrV6d///507NjRcExISAjz5s0jIiKCCRMmsGXLFkJDQ9HpdIZj+vbty6JFi9i0aRM9evRg3LhxfPzxx4bXY2Nj8fT0NPrsnO3Y2NiH1jZ+/HicnJwMi6+vb15euhAiv/nXgx5bofl4sHLQ9yn638v6PkYpt9SuLs94OVnzZbsqrOvfgKYVPdBlKczffYFGkzbz9YZTJKdlPv4kQgh1R5ktWrSIwYMHM2nSJMNtrP79+zNlyhTCw8Mf+p5z584RGBjIxo0badKkyUOP+fnnn+nRowfJyclotVqaNWtGQEAAs2bNMhxz7NgxgoKCOHbsGBUrVnzgHGlpaaSlpRm2ExMT8fX1lVFmQhRFSbGwfjgcXqLftnGFV0ZBtXeKxW20++0+F8f4NSeIvBgPgLu9Ff2alKX986WwlBFpwgQViVFmgwcPNrQSBQcH06lTJwYMGMD48eMf+Z7SpUvj7u7OmTNnHnnMCy+8QGZmJtHR0QB4eXlx7do1o2Nyth/V70ir1eLo6Gi0CCGKKAcvaPc/6LwKSlSE1FvwZx/46RW4Eql2dXnqhdJuLPuwLt93rEGAux03k9MZvuIozb7eyprDV2VEmhCPoGogSklJwexf/zozNzcnKyvrke+5dOkScXFxeHt7P/KYyMhIzMzM8PDwAKBOnTps3bqVjIwMwzEbNmygfPnyuLjIqAwhTIb/S/DBP9B8XPZttH3wQyNY9ZG+r1ExodFoaBHszfoBDRjTJgh3eyvO37xDz/kHeG3GDvacLz63DIXIK6oGolatWjF27FhWrVpFdHQ0y5YtY8qUKbRt2xaA5ORkBg8ezK5du4iOjiYiIoI2bdpQpkwZmjdvDug7TE+dOpWoqCjOnTvH/PnzGTBgAO+8844h7Lz99ttYWVnRtWtXjh49yuLFi/nmm28YOHCgatcuhFCJuSXU6QW990LwG4CiH64/rSYc/BX+4x9kRY2luRmd6vizeXBj+jYpi62VOQcvxPPmrJ28P3cfZ64nqV2iEIWGqn2IkpKSGD58OMuWLeP69ev4+PjQoUMHRowYgZWVFampqYSFhXHw4EHi4+Px8fGhWbNmjBkzxtAp+sCBA3z44YecOHGCtLQ0AgIC6NSpEwMHDjR6XtGhQ4fo1asXe/fuxd3dnT59+vDJJ5/kulZ5UrUQxdT5f2D1ILhxQr9d8nloOVk/R1oxcz3pLt9sPM2ivRfRZSmYaeDNWr4MeKUcno7WapcnRL6QqTvymAQiIYoxXQbsngmbv4T0ZNCYQe33ofEwsHFWu7o8d/ZGMhPXnmDdUX1fSmtLM95/qTQ9GpbGwdpS5eqEyFsSiPKYBCIhTEDiFVj/GRz5Q79t6w6vjIaqHYrdaDSA/TG3GL/6BPti9P2nXO2s6PNyGTq+4IeVRfG7XmGaJBDlMQlEQpiQc1tg9WC4eVK/7fui/jaaV7C6deUDRVHYcOwaX649wbkbdwAo5WrL4OblaRnsjZmZRuUKhXg2EojymAQiIUxMZjrsngGbJ0DGHf1ttOe7Q6OhxfI2WqYuiyX7LvH1xlPcSNI/g61KSSeGhFagbqC7ytUJ8fQkEOUxCURCmKiEy7B+GBxdpt+284BmY6DKW6Apfq0nKemZ/PTPeWZuOcuddP2MAI3Ll+CT0ApU8JLffaLokUCUxyQQCWHizm7S30aLO63fLlUHWkwGr8rq1pVPbianMS3iNPN3XyAzS0GjgXY1SjLwlXL4ONuoXZ4QuSaBKI9JIBJCkJkOu76DLRMhIwU05vrbaI2HgrWT2tXli+ibd5i07iSrDl8FQGthxqBm5Xm/fgCaYthCJoofCUR5TAKREMIg4RKs+xSOrdBv23lAsy+gypvF8jYaQOTFeMavPs7u7Kdcv1mrJF+EBctoNFHoSSDKYxKIhBAPOBMBaz6GuOy5Ff3q6W+jeVZSt658oigK83bGMOqvo2Qp8GJpV2a+UxNnWyu1SxPikYrE5K5CCFGklWkCPXdAk8/B0hZitsPMl2Dtp3A3Ue3q8pxGoyG8rj8/d66Ng9aCXedu0fb7HZy7kax2aUI8MwlEQgjxLCy0UH8g9NoDFVuDotP3M5peGw79BsWwEb5ReQ/++LAuJV1sOH/zDm2/38GOszfVLkuIZyKBSAgh8oKzL7z1C7zzB7gGQnIsLH0f5rwK14+rXV2eK+fpwPJe9ahRypmE1Aze/WkPi/deULssIZ6aBCIhhMhLZZrChzvh5eFgYQMx2/S30dYNg7TidWvJ3V7Lgm4v0rqqD5lZCp/8cZjxq4+jyyp+rWKi+JNAJIQQec1CCw0GQe89UOFVyMqEndPhlzC4m6B2dXnK2tKcb9pXY0DTcgDM2nqOD37dT0p6psqVCfFkJBAJIUR+cS4F7edDx9/BxgUu7YVfXit2oUij0dCvaVm+7VAdKwszNhy7xhszd3I1IVXt0oTINQlEQgiR38q+Au/+qQ9Fl/cVy1AE0LqqD4u6v4i7vRVHryQS9t12Dl8qftcpiicJREIIURC8q5hEKKpRyoVlH9ajvKcD1xLTeGPWDtYeuap2WUI8lgQiIYQoKN5VIPwvsHHNDkVtITVe7arynK+rLb/3rEOj8iW4m5HFB78eYMbms8hzgEVhJoFICCEKklcwhP+ZHYr2w6+vFctQ5GBtyY/v1qJzXX8AJqw9wce/HyI9M0vdwoR4BAlEQghR0P4dioppS5GFuRkjWwcxuk0Q5mYaftt/iXd+2s3tO+lqlybEAyQQCSGEGryC9bfPbN3gyoFiG4oA3q1zb7qPPedv0fb77ZyV6T5EISOBSAgh1OJVWd/R2gRCUcNyJQzTfUTHpdD2u+3sOCPTfYjCQwKREEKoyavyv1qKwiD1ttpV5Yuc6T5q+rmQeDeTd3/ew6I9Mt2HKBwkEAkhhNo8g+4LRQezW4qKZyhyt9cy//0XaFNNP93HkKWHGSfTfYhCQAKREEIUBv8ORfPCim0osrY0Z+pb96b7+GHrOXr8sp87aTLdh1CPBCIhhCgsPIMgfCXYusPVyGIdiv493cfG4zLdh1CXBCIhhChMPCtltxTlhKI2xTYUgfF0H8euJtJm+nYOXYpXuyxhgiQQCSFEYWMUiqL0oSjlltpV5ZsapVxY3ks/3cf1pDTenLVTpvsQBU4CkRBCFEaelaDzynuh6JewYh2KSro8ON3H95vPyHQfosBIIBJCiMLKo6I+FNmVMImWon9P9zFx7UkGy3QfooBIIBJCiMLMo6K+o7VdCYg9VOxDUc50H2Oyp/v4Xab7EAVEApEQQhR2HhVMKhQBdPrXdB9hMt2HyGcSiIQQoigwhCKP7FDUutiHooblSrD0w7r4utoQkz3dx3aZ7kPkEwlEQghRVHhUyO5T5AGxh00iFJX1dGD5h/em+wj/eQ8LZboPkQ8kEAkhRFFSorxxKJpb/EORW/Z0H22rP0dmlsLQpYcZu+qYTPch8pQEIiGEKGruD0XXskPRnTi1q8pX1pbmTHmzKgNf0U/38b9/zst0HyJPSSASQoiiqER56LzqXiia16bYhyKNRkPfJmWZ1qE62uzpPl6fuZMr8TLdh3h2EoiEEKKoKlFOH4rsPbNDUfFvKQJodd90H8evJhL2nUz3IZ6dBCIhhCjKSpTTjz6z94RrR0wmFFXPnu6jgte96T5WH5bpPsTTk0AkhBBFnVFL0RGY28okQlFJF1t++6AOjbOn+/hw/gG+2yTTfYinI4FICCGKA/ey2aHIC64fzQ5Fxf+ZPQ7WlvwYXpsu9fwBmLTuJIN+O0Rapk7dwkSRI4FICCGKC/ey+tFnhlDU2iRCkbmZhs9bBTEmrDLmZhr+OHCJTj/u4ZZM9yGegAQiIYQoTh5oKTKNUATQ6UU/ZudM9xF9i7bfb+fMdZnuQ+SOqoFIp9MxfPhwAgICsLGxITAwkDFjxhjd/+3cuTMajcZoCQkJeej50tLSqFatGhqNhsjISKPXDh06RP369bG2tsbX15eJEyfm56UJIYR63MvoQ5GD973bZ8k31K6qQDT413Qfr30v032I3FE1EE2YMIEZM2Ywffp0jh8/zoQJE5g4cSLTpk0zOi4kJISrV68aloULFz70fB9//DE+Pj4P7E9MTKRZs2b4+fmxf/9+Jk2axMiRI/nhhx/y5bqEEEJ17mX0o88cvOH6Mf3oMxMJRTnTfdTKnu7j3Z/3sGC3TPch/puqgWjHjh20adOGli1b4u/vz+uvv06zZs3Ys2eP0XFarRYvLy/D4uLi8sC51qxZw/r165k8efIDr82fP5/09HR+/vlngoKCaN++PX379mXKlCn5dm1CCKE6o5aiYybVUuRmr2V+N/10H7oshU+XHWbMSpnuQzyaqoGobt26REREcOrUKQCioqLYtm0boaGhRsdt3rwZDw8PypcvT8+ePYmLMx5Oeu3aNbp168Yvv/yCra3tA5+zc+dOGjRogJWVlWFf8+bNOXnyJLdv335obWlpaSQmJhotQghR5LgFZociH7hx3KRCkdZCP93HR9nTffy07Tw9ftkn032Ih1I1EA0ZMoT27dtToUIFLC0tqV69Ov3796djx46GY0JCQpg3bx4RERFMmDCBLVu2EBoaik6nH1KpKAqdO3fmgw8+oFatWg/9nNjYWDw9PY325WzHxsY+9D3jx4/HycnJsPj6+ubFJQshRMFzC9SPPjOEoldNJhRpNBr6NCnL9Ldzpvu4LtN9iIdSNRAtWbKE+fPns2DBAg4cOMDcuXOZPHkyc+fONRzTvn17WrduTXBwMGFhYaxcuZK9e/eyefNmAKZNm0ZSUhJDhw7N09qGDh1KQkKCYbl48WKenl8IIQqUUSg6kR2KrqtdVYF5tUrOdB9ajl9NpI1M9yH+RdVANHjwYEMrUXBwMJ06dWLAgAGMHz/+ke8pXbo07u7unDlzBoC///6bnTt3otVqsbCwoEyZMgDUqlWL8PBwALy8vLh27ZrReXK2vby8Hvo5Wq0WR0dHo0UIIYq0nFDk+Fx2KGplUqFIP91HXSp4OXAjKY3wn/dIS5EwUDUQpaSkYGZmXIK5uTlZWVmPfM+lS5eIi4vD29sbgG+//ZaoqCgiIyOJjIxk9erVACxevJixY8cCUKdOHbZu3UpGRobhPBs2bKB8+fIP7aAthBDFllsghP9lsqGopIstv/esS5CPI7dTMui94ADpmY/+myNMh6qBqFWrVowdO5ZVq1YRHR3NsmXLmDJlCm3btgUgOTmZwYMHs2vXLqKjo4mIiKBNmzaUKVOG5s2bA1CqVCkqV65sWMqV03eeCwwMpGTJkgC8/fbbWFlZ0bVrV44ePcrixYv55ptvGDhwoDoXLoQQavp3S9GcVyHp2uPfV0zYay2Y0bEmDtYWHLgQz5drTqhdkigEVA1E06ZN4/XXX+fDDz+kYsWKDBo0iB49ejBmzBhA31p06NAhWrduTbly5ejatSs1a9bkn3/+QavV5vpznJycWL9+PefPn6dmzZp89NFHjBgxgu7du+fXpQkhROHmWvpeKLp5Ut9SZEKhqJSbLVPerAbAz9vPs+bwVXULEqrTKDItcK4kJibi5OREQkKC9CcSQhQft87BnFaQeAncy2U/zNHz8e8rJsavOc6sLeew11rwV5+XCHC3U7skkcdy+/db5jITQghTZmgpKgk3T+lHnyU9/HEkxdHgZuV5PsCV5LRMev66n9R0ndolCZVIIBJCCFPnGvCvUNTKZEKRhbkZ0ztUx91ey4nYJEasOKJ2SUIlEoiEEELcC0VOvvpQNMd0Woo8HK35tkM1zDTw2/5LLNkrz50zRRKIhBBC6N0fiuJOm1QoqhvozkfNygMwfMURjl5JULkiUdAkEAkhhLjHxd9kQ1HPhoE0Ll+CtMwsPpx/gMS7GY9/kyg2JBAJIYQwZghFpbJDUUtILP7D0s3MNHz9VjWec7YhJi6Fwb9FIQOxTYcEIiGEEA8yCkVn9KPPTCAUOdta8X3HGliaa1h39Bo/bTuvdkmigEggEkII8XAufiYZiqr6OjPi1UoAjF9zgr3Rt1SuSBQECURCCCEeLScUOWeHojktIfGK2lXlu3de9KN1VR90WQq9FxzgZnKa2iWJfCaBSAghxH9z8dM/wdq5FNw6C4s6gi5T7arylUajYfxrwZTxsOdaYhr9Fh1ElyX9iYozCURCCCEeLycUWTvDlQOwbYraFeU7O60FMzrWwMbSnO1n4vhm4ym1SxL5SAKREEKI3HHxgxaT9etbJsCVSFXLKQhlPR34sl0wAN/+fYbNJ6+rXJHILxKIhBBC5F7w61CpDWRlwrIPIOOu2hXluzbVnuOdF0sBMGBxJJfjU1WuSOQHCURCCCFyT6OBllPArgTcOA6bxqpdUYEY/molqpR04nZKBr3mHyA9M0vtkkQek0AkhBDiydi5Q6tv9es7psGFXerWUwC0FuZ893YNHK0tiLwYz7jVx9UuSeQxCURCCCGeXIUWUK0joOhvnaUlq11RvvN1tWXKm9UAmLMjmpWHiv/jB0yJBCIhhBBPJ2S8fs6z2+dhwwi1qykQTSt50rNRIACf/H6IszeKfxA0FRKIhBBCPB1rJ2jznX59309wJkLdegrIR6+U44UAV+6k6+j5635S0ov3M5lMhQQiIYQQT690Q3i+h359RW9Iva1uPQXAwtyMaW9Xp4SDllPXkvls2RGZBLYYkEAkhBDi2TQdCa6BkHQF1nyidjUFwsPBmmkdqmOmgaUHL7No70W1SxLPSAKREEKIZ2NlC21ngcYMDi2GY3+qXVGBeLG0G4ObVwDg8z+PcuRygsoViWchgUgIIcSz860N9frr11cOgOQbqpZTUHo0KE3Tih6kZ2bRc/5+ElIy1C5JPCUJREIIIfJGoyHgWRlSbsLK/mAC/WrMzDR89UY1SrrYcPFWKh/9FiX9iYooCURCCCHyhoVWf+vMzBJOrISoRWpXVCCcbC2Z0bEmVuZmbDx+jR+2nlO7JPEUJBAJIYTIO16VofFQ/fqajyHhkrr1FJDgkk583roSABPXnWT3uTiVKxJPSgKREEKIvFW3H5SsDWmJsKIXZJnGvF9vP1+KttWfQ5el0GfhQW4kpaldkngCEoiEEELkLXMLCJsJFjZwbrP+oY0mQKPRMLZtZcp62HM9KY2+Cw+iy5L+REWFBCIhhBB5z70MvDJKv75hBMSdVbeeAmJrZcGMd2pga2XOznNxfL3hlNoliVySQCSEECJ/1O4GAQ0gIwWW94QsndoVFYgyHg582a4KANM3neHvE9dUrkjkhgQiIYQQ+cPMDNp8D1pHuLgbdnyrdkUFpnVVH96t4wfAgMVRXLqdonJF4nEkEAkhhMg/zr4Q8qV+fdM4uHZU3XoK0LCWFala0omE1Ax6zT9AWqZptJAVVRKIhBBC5K9qb0O5UNClw9IekJmudkUFQmthzncda+BkY0nUpQTGrjqudkniP0ggEkIIkb80Gmj1Ddi4wrXDsHWi2hUVmJIutkx9qxoA83bGsCLysroFiUeSQCSEECL/OXjCq1/r1/+ZApf2q1tPAWpcwYPejcsAMHTpYc5cT1K5IvEwEoiEEEIUjKAwCH4DFB0s6wEZqWpXVGAGvFKOuoFupKTr+ODXA9xJy1S7JPEvEoiEEEIUnBaTwMEb4k7DxlFqV1NgzM00fNO+Oh4OWs5cT2bYssMyCWwhI4FICCFEwbFxgdbT9eu7Z8D5rerWU4BKOGiZ/nYNzM00LI+8wvzdF9QuSdxHApEQQoiCVbYp1OysX1/eC+4mqlpOQXo+wJVPQsoDMPqvYxy6FK9uQcJAApEQQoiC1+wLcPaDhAuw7lO1qylQ3eqX5pVKnqTrsuj56wHiU0zjMQSFnQQiIYQQBU/rAG1nAho4+AucWqd2RQVGo9Ew+Y2q+LracDk+lY+WRJElk8Cq7qkC0cWLF7l06ZJhe8+ePfTv358ffvghzwoTQghRzPnVhTq99Ot/9oGUW+rWU4CcbCyZ0bEmVhZmRJy4zqyt59QuyeQ9VSB6++232bRpEwCxsbG88sor7Nmzh2HDhjF69Ohcn0en0zF8+HACAgKwsbEhMDCQMWPGGPW879y5MxqNxmgJCQkxOk/r1q0pVaoU1tbWeHt706lTJ65cuWJ0zKFDh6hfvz7W1tb4+voycaLpPBhMCCEKrZeHQ4kKkHwNVg1Uu5oCVfk5J0a1DgJg0roT7Dwbp3JFpu2pAtGRI0d4/vnnAViyZAmVK1dmx44dzJ8/nzlz5uT6PBMmTGDGjBlMnz6d48ePM2HCBCZOnMi0adOMjgsJCeHq1auGZeHChUavN27cmCVLlnDy5En++OMPzp49y+uvv254PTExkWbNmuHn58f+/fuZNGkSI0eOlBYtIYRQm6W1/taZxhyOLoPDv6tdUYFqX9uX12o8R5YCfRYe5HriXbVLMlkWT/OmjIwMtFotABs3bqR169YAVKhQgatXr+b6PDt27KBNmza0bNkSAH9/fxYuXMiePXuMjtNqtXh5eT3yPAMGDDCs+/n5MWTIEMLCwsjIyMDS0pL58+eTnp7Ozz//jJWVFUFBQURGRjJlyhS6d++e63qFEELkA5/q0GAwbPkSVn0EfvXA0VvtqgqERqPhi7DKHL2cyMlrSfRZeJD577+Ahbl08S1oT/UVDwoKYubMmfzzzz9s2LDBcAvrypUruLm55fo8devWJSIiglOnTgEQFRXFtm3bCA0NNTpu8+bNeHh4UL58eXr27Elc3KObFW/dusX8+fOpW7culpaWAOzcuZMGDRpgZWVlOK558+acPHmS27dvP/Q8aWlpJCYmGi1CCCHySYNB4F0N7sbDX33BhB5aaGtlwffv1MDOypzd52/x1YZTapdkkp4qEE2YMIFZs2bRqFEjOnToQNWqVQH4888/DbfScmPIkCG0b9+eChUqYGlpSfXq1enfvz8dO3Y0HBMSEsK8efOIiIhgwoQJbNmyhdDQUHQ6ndG5PvnkE+zs7HBzc+PChQusWLHC8FpsbCyenp5Gx+dsx8bGPrS28ePH4+TkZFh8fX1zfV1CCCGekLkltJ0F5lo4vR4OzFO7ogIVWMKeCa9XAWDG5rNsPHZN5YpMj0Z5ymeH63Q6EhMTcXFxMeyLjo7G1tYWDw+PXJ1j0aJFDB48mEmTJhluY/Xv358pU6YQHh7+0PecO3eOwMBANm7cSJMmTQz7b968ya1bt4iJiWHUqFE4OTmxcuVKNBoNzZo1IyAggFmzZhmOP3bsGEFBQRw7doyKFSs+8DlpaWmkpaUZthMTE/H19SUhIQFHR8dcXZ8QQogntGMarP8MrOyh53Zw8Ve7ogI18s+jzNkRjaO1Bav61sfX1Vbtkoq8xMREnJycHvv3+6laiFJTU0lLSzOEoZiYGKZOncrJkydzHYYABg8ebGglCg4OplOnTgwYMIDx48c/8j2lS5fG3d2dM2fOGO13d3enXLlyvPLKKyxatIjVq1eza9cuALy8vLh2zTht52w/qm+SVqvF0dHRaBFCCJHPXvwQStWF9GT9U6yzstSuqEB92qIi1XydSbybSc/5+7mboXv8m0SeeKpA1KZNG+bN0zdnxsfH88ILL/DVV18RFhbGjBkzcn2elJQUzMyMSzA3NyfrP/4HuHTpEnFxcXh7P7rDXc77c1p46tSpw9atW8nIyDAcs2HDBsqXL2/UwiWEEEJlZuYQ9j1Y2kHMNv18ZybEysKM7zrWwMXWkiOXExmz8pjaJZmMpwpEBw4coH79+gD8/vvveHp6EhMTw7x58/j2229zfZ5WrVoxduxYVq1aRXR0NMuWLWPKlCm0bdsWgOTkZAYPHsyuXbuIjo4mIiKCNm3aUKZMGZo3bw7A7t27mT59OpGRkcTExPD333/ToUMHAgMDqVOnDqB/bpKVlRVdu3bl6NGjLF68mG+++YaBA03rmRdCCFEkuAZA8y/06xtHwY2T6tZTwJ5ztuHrt6qh0cD83RdYdvDS498kntlTBaKUlBQcHBwAWL9+Pa+99hpmZma8+OKLxMTE5Po806ZN4/XXX+fDDz+kYsWKDBo0iB49ejBmzBhA31p06NAhWrduTbly5ejatSs1a9bkn3/+MQz7t7W1ZenSpTRp0oTy5cvTtWtXqlSpwpYtWwzHODk5sX79es6fP0/NmjX56KOPGDFihAy5F0KIwqpmFyjTFHRpsKwH6DLVrqhANSrvQZ/GZQD4dOkRTl1LUrmi4u+pOlVXqVKF999/n7Zt21K5cmXWrl1LnTp12L9/Py1btnzkyK2iLLedsoQQQuSRxCvw/YtwNwEaD4OGH6tdUYHSZSm8+/Nutp+Jo3QJO/7s/RL22qd6fKBJy9dO1SNGjGDQoEH4+/vz/PPPG25NrV+/nurVqz9dxUIIIcT9HH2gxVf69S0T4EqkquUUNHMzDd+0r46no5ZzN+4wdOlhnnJguMiFpx52Hxsby9WrV6lataqhY/SePXtwdHSkQoUKeVpkYSAtREIIoQJFgd/C4dgKKFERum/WT/dhQvZF3+KtH3ahy1IY3SaId+v4q11SkZKvLUSgH65evXp1rly5wqVL+g5fzz//fLEMQ0IIIVSi0UDLr8GuBNw4DpvGql1Rgavl78rQUP3f1jErjxF5MV7dgoqppwpEWVlZjB49GicnJ/z8/PDz88PZ2ZkxY8b855B5IYQQ4onZuUGr7BHMO6ZBzE5161FB15cCaB7kSYZOodf8A9y+k652ScXOUwWiYcOGMX36dL788ksOHjzIwYMHGTduHNOmTWP48OF5XaMQQghTV6EFVOsIKLD8A0hLVruiAqXRaJj0RlX83Gy5HJ/KwCWRZGVJf6K89FR9iHx8fJg5c6ZhlvscK1as4MMPP+Ty5ct5VmBhIX2IhBBCZXcTYEY9SLgItbrCq1PUrqjAHb2SwGvf7yAtM4vBzcvTK3tovni0fO1DdOvWrYf2FapQoQK3bt16mlMKIYQQ/83aCdp8p1/f9xOciVC3HhUE+Tgxpk1lAL5af5IdZ26qXFHx8VSBqGrVqkyfPv2B/dOnT6dKlSrPXJQQQgjxUKUbwvM99OsrekPqbXXrUcGbtX15o2ZJshTou+gg1xLvql1SsfBUt8y2bNlCy5YtKVWqlOEZRDt37uTixYusXr3aMK1HcSK3zIQQopBIT4GZL8Gts1DlLXjtB7UrKnCp6Trafr+dE7FJPO/vyoJuL2Bh/tQDx4u1fL1l1rBhQ06dOkXbtm2Jj48nPj6e1157jaNHj/LLL788ddFCCCHEY1nZQttZoDGDQ4vh2J9qV1TgbKzMmfFOTeyszNkTfYvvN59Vu6Qi76kfzPgwUVFR1KhRA51Ol1enLDSkhUgIIQqZjaNg2xSwdYMPd4N9CbUrKnB/7L/ER79FYW6mYUmPOtT0c1G7pEIn3x/MKIQQQqiq0RDwrAwpcbCyv/6p1ibmtRrP0aqqD7oshf6LD5J0N0PtkoosCURCCCGKJgut/taZmSWcWAlRi9SuqMBpNBq+CKvMc842XLyVyucrjqpdUpElgUgIIUTR5VUZGg/Vr6/5GBIuqVuPCpxsLJnavhpmGlh68DIrIovfswALgsWTHPzaa6/95+vx8fHPUosQQgjx5Or2g5Nr4NJeWNEL3lkGZqb17/3a/q70blyGb/8+w2fLjlCjlAu+rrZql1WkPNFPjJOT038ufn5+vPvuu/lVqxBCCPEgcwsImwkWNnBus/6hjSaob5OyVC/lTFJaJgMWR5Kpk7lFn0SejjIrzmSUmRBCFHK7Z+lvm1nawgfbwC1Q7YoK3IW4FFp8+w/JaZkMfKUcfZuUVbsk1ckoMyGEEKaldjcIaAAZKbC8J2QVv0fAPE4pN1tGtwkC4JuI0+yPMb0neT8tCURCCCGKBzMzaPM9aB3h4m7Y8a3aFamibfXnaC1D8Z+YBCIhhBDFh7MvhHypX980Dq6Z3jB0jUbDF21lKP6TkkAkhBCieKn2NpRvAbp0WNoDMtPVrqjAOVpb8o0MxX8iEoiEEEIULxoNvDoVbFzh2mHYMkHtilRRy9+V3i/rO1V/tuwIF2+lqFxR4SaBSAghRPHj4Amvfq1f3zYFLu1Ttx6V9H25DDVkKH6uSCASQghRPAWFQfAboGTBsg8gI1XtigqchbkZ37Svjr3Wgn0xt/lu01m1Syq0JBAJIYQovlpMAgdviDsNG0epXY0qfF1tGROmH4r/7d8yFP9RJBAJIYQovmxcoPV0/fruGXB+q7r1qKRt9ZK0qSZD8f+LBCIhhBDFW9mmULOLfn15L7ibqG49KhkTVpmSLvqh+CNkKP4DJBAJIYQo/pqNAWc/SLgA64aqXY0qcobim5tpWCZD8R8ggUgIIUTxp3WAtjMBDRz8FU6uVbsiVdT0c6XPy2UAGYr/bxKIhBBCmAa/ulCnl379r76QckvdelTSu3EZavm5kJSWSX8Zim8ggUgIIYTpeHk4lKgAyddg5QBQFLUrKnAW5mZ8/VY1HLQW7I+5zfRNZ9QuqVCQQCSEEMJ0WFrrb52ZWcCx5XD4N7UrUoWvqy1ftK0MwLcRp9kfY5qtZfeTQCSEEMK0+FSHhkP066sGQcIldetRSZtqz9G2+nNkKdBvUSSJJj4UXwKREEII0/PSAChZG9ISYHlPyDLNfjSj2wTh62rDpdupjFh+RO1yVCWBSAghhOkxt4C2s8DSVv+wxt0z1a5IFQ7Wlkx9qzrmZhqWR15h+UHTHYovgUgIIYRpcguE5mP16xtHwvXjqpajlpp+LvR9uSwAny033aH4EoiEEEKYrppdoGwz0KXB0m6Qma52Raro1TiQWn4uJKdl0m/RQZMcii+BSAghhOnSaPRzndm4Quxh2Dxe7YpUcf9Q/AMX4pn2t+kNxZdAJIQQwrQ5eEKrb/Tr26fChV2qlqOW+4fiT/v7NPuiTWsovgQiIYQQolJrqPo2KFmwrAekJaldkSraVHuO10x0KL4EIiGEEAIg9EtwKgW3o2Hdp2pXo5pRbYIo5WrL5fhUhpvQUHwJREIIIQSAtRO0nQFo4MA8OLFa7YpU4WBtydT21TA307Ai8grLDprGgytVDUQ6nY7hw4cTEBCAjY0NgYGBjBkzBuW+uWU6d+6MRqMxWkJCQgyvR0dH07VrV6NzfP7556SnG48UOHToEPXr18fa2hpfX18mTpxYYNcphBCiiPB/Cer20a//2QeSb6hbj0pqlHKhXxP9UPzhy49yIa74D8W3UPPDJ0yYwIwZM5g7dy5BQUHs27ePLl264OTkRN++fQ3HhYSEMHv2bMO2Vqs1rJ84cYKsrCxmzZpFmTJlOHLkCN26dePOnTtMnjwZgMTERJo1a0bTpk2ZOXMmhw8f5r333sPZ2Znu3bsX3AULIYQo/F7+DM5EwPWj8FdfaL9APxrNxPRqXIZ/Tt9gb/Rt+i8+yJIedbAwL743ljSKot5Uv6+++iqenp789NNPhn3t2rXDxsaGX3/9FdC3EMXHx7N8+fJcn3fSpEnMmDGDc+fOATBjxgyGDRtGbGwsVlZWAAwZMoTly5dz4sSJXJ0zMTERJycnEhIScHR0zHUtQgghiqDYI/C/xqBLh9bToMa7alekiku3Uwj95h+S7mbSt0lZBr5STu2Snlhu/36rGvXq1q1LREQEp06dAiAqKopt27YRGhpqdNzmzZvx8PCgfPny9OzZk7i4uP88b0JCAq6urobtnTt30qBBA0MYAmjevDknT57k9u3bDz1HWloaiYmJRosQQggT4VUZXh6uX187FG6dV7celZR0sWVs22AApv99mr3FeCi+qoFoyJAhtG/fngoVKmBpaUn16tXp378/HTt2NBwTEhLCvHnziIiIYMKECWzZsoXQ0FB0Ot1Dz3nmzBmmTZtGjx49DPtiY2Px9PQ0Oi5nOzY29qHnGT9+PE5OTobF19f3WS9XCCFEUVKnF/jVg/RkWPYBZD38705x17qqD6/V0A/F778okoTU4jkUX9VAtGTJEubPn8+CBQs4cOAAc+fOZfLkycydO9dwTPv27WndujXBwcGEhYWxcuVK9u7dy+bNmx843+XLlwkJCeGNN96gW7duz1Tb0KFDSUhIMCwXL158pvMJIYQoYszMIWwGWDnAxV2w/Ru1K1LN6DaVjYbiq9jbJt+oGogGDx5saCUKDg6mU6dODBgwgPHjH/3o9NKlS+Pu7s6ZM8aPFb9y5QqNGzembt26/PDDD0aveXl5ce3aNaN9OdteXl4P/RytVoujo6PRIoQQwsS4+EGL7FHJm8bB1Sh161GJvdaCb7KH4v8ZdYVlBy+rXVKeUzUQpaSkYGZmXIK5uTlZWY+eVO7SpUvExcXh7e1t2Hf58mUaNWpEzZo1mT179gPnrFOnDlu3biUj414z34YNGyhfvjwuLi55dDVCCCGKpaodoGIryMqApd0h467aFamieikX+mcPxR+xovgNxVc1ELVq1YqxY8eyatUqoqOjWbZsGVOmTKFt27YAJCcnM3jwYHbt2kV0dDQRERG0adOGMmXK0Lx5c+BeGCpVqhSTJ0/mxo0bxMbGGvUNevvtt7GysqJr164cPXqUxYsX88033zBw4EBVrlsIIUQRotHAq9+AnQfcOAERo9WuSDUfNi7D8/6uJKdl0m/xQTJ0j27AKGpUHXaflJTE8OHDWbZsGdevX8fHx4cOHTowYsQIrKysSE1NJSwsjIMHDxIfH4+Pjw/NmjVjzJgxhk7Rc+bMoUuXLg89//2XdujQIXr16sXevXtxd3enT58+fPLJJ7muVYbdCyGEiTu1Hha8oV9/dwWUbqRqOWq5HJ9KyNSt+qH4L5dhYLPyapf0n3L791vVQFSUSCASQgjBX/1h/2xwfA567gAbZ7UrUsVfUVfos/AgZhpY1L0Ozwe4Pv5NKikSzyESQgghipRmX4BraUi8DGs+Vrsa1bSq6kO7GiXJUmDA4uIxFF8CkRBCCJFbWnto+wNozODQYjiyVO2KVDOqTRB+bvqh+J8Vg6H4EoiEEEKIJ+FbG+oP0q+vHACJV9StRyX2WgumvqUfiv9X1BWWHijaQ/ElEAkhhBBPquHH4F0N7sbDil5QxFtHnlb1Ui4MaJozFP8IMXF3VK7o6UkgEkIIIZ6UuSW89j+wsIazf8PeH9WuSDU9G5Xh+QBX7qTr6LcossgOxZdAJIQQQjyNEuXglexnEq0fDjdOqVuPSszNNHz9VjUcrS2IvBjPtxGn1S7pqUggEkIIIZ5W7W5QujFkpsKy7qAr+qOtnsZzzjaMey0YgO82nWHP+VsqV/TkJBAJIYQQT8vMDMK+B2tnuHIQtk5WuyLVvFrFh9drFt2h+BKIhBBCiGfh6AOvTtGvb50El/apW4+KRra+NxR/2LLDRWoovgQiIYQQ4llVbgfBb4Ci008Am150R1s9C3utBd+0r46FmYaVh67yRxEaii+BSAghhMgLLSbpp/S4dVbfydpEVfN1ZsAr5QD4fMURom8WjXAogUgIIYTICzYu+v5EAPt+gtMb1K1HRR80DOSFnKH4i4vGUHwJREIIIUReKd0IXuipX1/RC+7EqVqOWu4fih91MZ5vNhb+ofgSiIQQQoi81PRzcC8PyddgZX+TfYq1j7MN41+rAsB3m8+w+1zhDocSiIQQQoi8ZGkDr/0AZhZw/E/9JLAmqmUVb96oWRIlZyh+SuEdii+BSAghhMhrPtWg0VD9+urBEH9B1XLUNLJ1EP5utlxJuMunywvvUHwJREIIIUR+qNcffF+AtERY1hOyCn/H4vxgd99Q/FWHrvL7/ktql/RQEoiEEEKI/GBuAW1ngqUdxGyDXd+pXZFqqt4/FP/Po4VyKL4EIiGEECK/uJaGkHH69YjRcO2ouvWoKGcofkq6jn6LDha6ofgSiIQQQoj8VCMcyoWALl3/FOvMNLUrUkXOUHwnG0uiLiUwdeMptUsyIoFICCGEyE8aDbSeBrZucO0IbBqndkWq0Q/FDwbg+81n2VWIhuJLIBJCCCHym70HtPpWv779G4jZoW49KmoR7M2btQrfUHwJREIIIURBqPgqVH8HUGBZD7ibqHZFqvm8VRAB7nZcTbjLp8sKx1B8CURCCCFEQQn5Epz99M8lWjtU7WpUY6e1YOpb1fRD8Q9f5bdCMBRfApEQQghRULQO+qH4aCDyVzj+l9oVqaaqrzMDm+mH4o/88yjnVR6KL4FICCGEKEh+daFeP/36X/0g6Zq69aioR4NAXiytH4rfX+Wh+BKIhBBCiILW+FPwDIaUOPizj8lOAHv/UPzzN+9w5nqyarVIIBJCCCEKmoVWPwGsuRWcXgcH5qpdkWq8nWyY8U4N1vZvQEVvR9XqkEAkhBBCqMGzEjT5XL++9lOIO6tuPSqqG+iOj7ONqjVIIBJCCCHU8uKH4F8fMu7Asg9Al6l2RSZLApEQQgihFjMzCJsBWke4tAe2f612RSZLApEQQgihJmdfaDFJv775S7hyUN16TJQEIiGEEEJtVd6CSm0gK1M/AWxGqtoVmRwJREIIIYTaNBp4dSrYe8HNU7BxpNoVmRwJREIIIURhYOsKbb7Tr++eCWc3qVuPiZFAJIQQQhQWZZtC7ff168s/hNTb6tZjQiQQCSGEEIXJK6PBrQwkXYFVg9SuxmRIIBJCCCEKEys7aPsDaMzhyO9w+He1KzIJEoiEEEKIwqZkTWgwWL++aiAkXFa3HhMggUgIIYQojBoMAp8acDcBVnwIWerNBG8KJBAJIYQQhZG5pX4CWAsbOLcZ9v5P7YqKNVUDkU6nY/jw4QQEBGBjY0NgYCBjxoxBURTDMZ07d0aj0RgtISEhRucZO3YsdevWxdbWFmdn54d+1oULF2jZsiW2trZ4eHgwePBgMjNlzhghhBCFmHtZaDZGv75hBNw4qW49xZiFmh8+YcIEZsyYwdy5cwkKCmLfvn106dIFJycn+vbtazguJCSE2bNnG7a1Wq3RedLT03njjTeoU6cOP/300wOfo9PpaNmyJV5eXuzYsYOrV6/y7rvvYmlpybhx4/LvAoUQQohnVft9OLkGzkbA0m7QdSNYWKldVbGjaiDasWMHbdq0oWXLlgD4+/uzcOFC9uzZY3ScVqvFy8vrkecZNWoUAHPmzHno6+vXr+fYsWNs3LgRT09PqlWrxpgxY/jkk08YOXIkVlbygyWEEKKQ0mj0D2ycUQeuRsHWifDyZ2pXVeyoesusbt26REREcOrUKQCioqLYtm0boaGhRsdt3rwZDw8PypcvT8+ePYmLi3uiz9m5cyfBwcF4enoa9jVv3pzExESOHj360PekpaWRmJhotAghhBCqcPSGV7/Wr//zFVzc89/HiyemaiAaMmQI7du3p0KFClhaWlK9enX69+9Px44dDceEhIQwb948IiIimDBhAlu2bCE0NBSdTpfrz4mNjTUKQ4BhOzY29qHvGT9+PE5OTobF19f3Ka5QCCGEyCNBbfWTwCpZ+glg05LVrqhYUfWW2ZIlS5g/fz4LFiwgKCiIyMhI+vfvj4+PD+Hh4QC0b9/ecHxwcDBVqlQhMDCQzZs306RJk3yrbejQoQwcONCwnZiYKKFICCGEukInQvR2uH0e1g+DVt+oXVGxoWoL0eDBgw2tRMHBwXTq1IkBAwYwfvz4R76ndOnSuLu7c+bMmVx/jpeXF9euXTPal7P9qL5JWq0WR0dHo0UIIYRQlY0ztJ2hX98/B06tU7OaYkXVQJSSkoKZmXEJ5ubmZP3Hw6cuXbpEXFwc3t7euf6cOnXqcPjwYa5fv27Yt2HDBhwdHalUqdKTFy6EEEKoJaAB1OmtX1/RG+7cVLeeYkLVQNSqVSvGjh3LqlWriI6OZtmyZUyZMoW2bdsCkJyczODBg9m1axfR0dFERETQpk0bypQpQ/PmzQ3nuXDhApGRkVy4cAGdTkdkZCSRkZEkJ+vvrzZr1oxKlSrRqVMnoqKiWLduHZ999hm9evV6YAi/EEIIUei9PBxKVIQ71+HPvnDf8/vE09EoinpfxaSkJIYPH86yZcu4fv06Pj4+dOjQgREjRmBlZUVqaiphYWEcPHiQ+Ph4fHx8aNasGWPGjDHqJN25c2fmzp37wPk3bdpEo0aNAIiJiaFnz55s3rwZOzs7wsPD+fLLL7GwyF03qsTERJycnEhISJDbZ0IIIdR39RD872XIyoBmX0DdPmpXVCjl9u+3qoGoKJFAJIQQotDZ+yOs+gg05hD+F/jXU7uiQie3f79lLjMhhBCiqKrVNXsovg5+7wJJD3+UjHg8CURCCCFEUaXR6B/Y6FEJkq/Bb11Al6F2VUWSBCIhhBCiKLOygzd/ASsHuLADIkapXVGRJIFICCGEKOrcy0DY9/r1HdPg2J/q1lMESSASQgghioNKre+NNFv+Idw8rW49RYwEIiGEEKK4aDIS/OpBehIs7gTpd9SuqMiQQCSEEEIUF+YW8PrPYO8JN47DX/3koY25JIFICCGEKE4cvOD12fpnEx3+Tf+sIvFYEoiEEEKI4sa/HrySPdps7VC4tE/deooACURCCCFEcVSnN1RsrZ/aY8m7MgnsY0ggEkIIIYojjQbafAduZSDxMvzxPmTp1K6q0JJAJIQQQhRX1o76hzZa2sK5TbD5S7UrKrQkEAkhhBDFmWclaPWNfn3rRDi1Tt16CikJREIIIURxV+VNqN1Nv760O9yOVrWcwkgCkRBCCGEKmo+F52rB3Xh9J+uMu2pXVKhIIBJCCCFMgYUW3pwLNq5wNQrWDFa7okJFApEQQghhKpxKwus/ARo4MA8O/KJ2RYWGBCIhhBDClAS+DI2H6ddXD9K3FgkJREIIIYTJqf8RlG0GmXf1/YlSb6tdkeokEAkhhBCmxswM2s4C51L6EWfLekJWltpVqUoCkRBCCGGKbF31D20018KpNbD9a7UrUpUEIiGEEMJU+VSDlpP1639/Aec2q1mNqiQQCSGEEKasxrtQ/R1QsuD3rpBwWe2KVCGBSAghhDB1LSaDVzCk3ITfOkNmutoVFTgJREIIIYSps7TR9yeydoJLe2DDcLUrKnASiIQQQggBrgH6kWcAu2fC4d/VraeASSASQgghhF75UP0zigD+7AvXT6hbTwGSQCSEEEKIexoPg4CGkHEHFr8DaUlqV1QgJBAJIYQQ4h4zc2j3Ezj4QNxpWNEbFEXtqvKdBCIhhBBCGLMvAW/OBTMLOLYcds1Qu6J8J4FICCGEEA/yfR6aj9OvbxgOMTvVrSefSSASQgghxMM93x0qvw5ZmfrnEyVfV7uifCOBSAghhBAPp9FAq2+gRAVIjoXf3wNdptpV5QsJREIIIYR4NK29/qGNVvYQ/Q/8PUbtivKFBCIhhBBC/LcS5aDNdP369qlwfKWq5eQHCURCCCGEeLygtvBiL/368p4Qd1bdevKYBCIhhBBC5M4ro8D3RUhLhCXvQnqK2hXlGQlEQgghhMgdc0t4Yw7YlYBrR2DVwGLz0EYJREIIIYTIPUdveH02aMwgaiHsn612RXlCApEQQgghnkxAfWjyuX59zSdweb+69eQBCURCCCGEeHL1+kGFV0GXDkvCIeWW2hU9EwlEQgghhHhyGg2EfQ+upSHhIvzxPmTp1K7qqakaiHQ6HcOHDycgIAAbGxsCAwMZM2YMyn0dtDp37oxGozFaQkJCjM5z69YtOnbsiKOjI87OznTt2pXk5GSjYw4dOkT9+vWxtrbG19eXiRMnFsg1CiGEEMWWtZP+oY0WNnA2ArZOUruip2ah5odPmDCBGTNmMHfuXIKCgti3bx9dunTBycmJvn37Go4LCQlh9ux7nba0Wq3ReTp27MjVq1fZsGEDGRkZdOnShe7du7NgwQIAEhMTadasGU2bNmXmzJkcPnyY9957D2dnZ7p3714wFyuEEEIUR16VodVUWNYDNn8Jz9WCsk3VruqJqRqIduzYQZs2bWjZsiUA/v7+LFy4kD179hgdp9Vq8fLyeug5jh8/ztq1a9m7dy+1atUCYNq0abRo0YLJkyfj4+PD/PnzSU9P5+eff8bKyoqgoCAiIyOZMmWKBCIhhBDiWVVtDxd3w76fYen70GMrOJdSu6onouots7p16xIREcGpU6cAiIqKYtu2bYSGhhodt3nzZjw8PChfvjw9e/YkLi7O8NrOnTtxdnY2hCGApk2bYmZmxu7duw3HNGjQACsrK8MxzZs35+TJk9y+ffuhtaWlpZGYmGi0CCGEEOIRQr4En+qQelv/0MbMNLUreiKqBqIhQ4bQvn17KlSogKWlJdWrV6d///507NjRcExISAjz5s0jIiKCCRMmsGXLFkJDQ9Hp9B23YmNj8fDwMDqvhYUFrq6uxMbGGo7x9PQ0OiZnO+eYfxs/fjxOTk6GxdfXN8+uWwghhCh2LLTw5jywcYErB2HtELUreiKq3jJbsmQJ8+fPZ8GCBYbbWP3798fHx4fw8HAA2rdvbzg+ODiYKlWqEBgYyObNm2nSpEm+1TZ06FAGDhxo2E5MTJRQJIQQQvwX51Lw2o8w/3X97bOSz0O1DmpXlSuqthANHjzY0EoUHBxMp06dGDBgAOPHj3/ke0qXLo27uztnzpwBwMvLi+vXrxsdk5mZya1btwz9jry8vLh27ZrRMTnbj+qbpNVqcXR0NFqEEEII8Rhlm0Kj7NahlQMg9oi69eSSqoEoJSUFMzPjEszNzcnKynrkey5dukRcXBze3t4A1KlTh/j4ePbvv/eUzL///pusrCxeeOEFwzFbt24lIyPDcMyGDRsoX748Li4ueXlJQgghhGjwMZRpCpmpsPgdSI1Xu6LHUjUQtWrVirFjx7Jq1Sqio6NZtmwZU6ZMoW3btgAkJyczePBgdu3aRXR0NBEREbRp04YyZcrQvHlzACpWrEhISAjdunVjz549bN++nd69e9O+fXt8fHwAePvtt7GysqJr164cPXqUxYsX88033xjdEhNCCCFEHjEzg9f+B06+cPs8LP+w8E8Cq6goMTFR6devn1KqVCnF2tpaKV26tDJs2DAlLS1NURRFSUlJUZo1a6aUKFFCsbS0VPz8/JRu3bopsbGxRueJi4tTOnTooNjb2yuOjo5Kly5dlKSkJKNjoqKilJdeeknRarXKc889p3z55ZdPVGtCQoICKAkJCc920UIIIYSpuLRPUUa7K8rnjoryz9eqlJDbv98aRSnska1wSExMxMnJiYSEBOlPJIQQQuTWvtmwsj9ozODdP/UTwxag3P79lrnMhBBCCJF/anaGqm+DkgW/d4HEq2pX9FASiIQQQgiRfzQaaPkVeFaGOzfgt86gy3js2wqaBCIhhBBC5C8rW/1DG7WOcHEXbPhc7YoeIIFICCGEEPnPLRDaztSv7/oOji5Tt55/kUAkhBBCiIJRoSXU669fX9EbbpxStZz7SSASQgghRMF5eTj414f0ZFjSCdKS1a4IkEAkhBBCiIJkbgGv/wz2XnDjBPzVt1A8tFECkRBCCCEKlr0HvDkXzCzgyB+w5we1K5JAJIQQQggVlHoRXhmjX1/3KVzco2o5EoiEEEIIoY4Xe0JQW8jKhCXhkHxDtVIsVPtkIYQQQpg2jQZaT4NrR8HCGjJTVStFApEQQggh1KN1gHf+ALsSYGmjWhkSiIQQQgihLudSalcgfYiEEEIIISQQCSGEEMLkSSASQgghhMmTQCSEEEIIkyeBSAghhBAmTwKREEIIIUyeBCIhhBBCmDwJREIIIYQweRKIhBBCCGHyJBAJIYQQwuRJIBJCCCGEyZNAJIQQQgiTJ4FICCGEECZPZrvPJUVRAEhMTFS5EiGEEELkVs7f7Zy/448igSiXkpKSAPD19VW5EiGEEEI8qaSkJJycnB75ukZ5XGQSAGRlZXHlyhUcHBzQaDRql1PoJCYm4uvry8WLF3F0dFS7HJMn34/CR74nhYt8PwqX/Px+KIpCUlISPj4+mJk9uqeQtBDlkpmZGSVLllS7jELP0dFRfrkUIvL9KHzke1K4yPejcMmv78d/tQzlkE7VQgghhDB5EoiEEEIIYfIkEIk8odVq+fzzz9FqtWqXIpDvR2Ek35PCRb4fhUth+H5Ip2ohhBBCmDxpIRJCCCGEyZNAJIQQQgiTJ4FICCGEECZPApEQQgghTJ4EIvFMxo8fT+3atXFwcMDDw4OwsDBOnjypdlki25dffolGo6F///5ql2KyLl++zDvvvIObmxs2NjYEBwezb98+tcsySTqdjuHDhxMQEICNjQ2BgYGMGTPmsXNcibyzdetWWrVqhY+PDxqNhuXLlxu9rigKI0aMwNvbGxsbG5o2bcrp06cLpDYJROKZbNmyhV69erFr1y42bNhARkYGzZo1486dO2qXZvL27t3LrFmzqFKlitqlmKzbt29Tr149LC0tWbNmDceOHeOrr77CxcVF7dJM0oQJE5gxYwbTp0/n+PHjTJgwgYkTJzJt2jS1SzMZd+7coWrVqnz33XcPfX3ixIl8++23zJw5k927d2NnZ0fz5s25e/duvtcmw+5Fnrpx4wYeHh5s2bKFBg0aqF2OyUpOTqZGjRp8//33fPHFF1SrVo2pU6eqXZbJGTJkCNu3b+eff/5RuxQBvPrqq3h6evLTTz8Z9rVr1w4bGxt+/fVXFSszTRqNhmXLlhEWFgboW4d8fHz46KOPGDRoEAAJCQl4enoyZ84c2rdvn6/1SAuRyFMJCQkAuLq6qlyJaevVqxctW7akadOmapdi0v78809q1arFG2+8gYeHB9WrV+d///uf2mWZrLp16xIREcGpU6cAiIqKYtu2bYSGhqpcmQA4f/48sbGxRr+3nJyceOGFF9i5c2e+f75M7iryTFZWFv3796devXpUrlxZ7XJM1qJFizhw4AB79+5VuxSTd+7cOWbMmMHAgQP59NNP2bt3L3379sXKyorw8HC1yzM5Q4YMITExkQoVKmBubo5Op2Ps2LF07NhR7dIEEBsbC4Cnp6fRfk9PT8Nr+UkCkcgzvXr14siRI2zbtk3tUkzWxYsX6devHxs2bMDa2lrtckxeVlYWtWrVYty4cQBUr16dI0eOMHPmTAlEKliyZAnz589nwYIFBAUFERkZSf/+/fHx8ZHvh5BbZiJv9O7dm5UrV7Jp0yZKliypdjkma//+/Vy/fp0aNWpgYWGBhYUFW7Zs4dtvv8XCwgKdTqd2iSbF29ubSpUqGe2rWLEiFy5cUKki0zZ48GCGDBlC+/btCQ4OplOnTgwYMIDx48erXZoAvLy8ALh27ZrR/mvXrhley08SiMQzURSF3r17s2zZMv7++28CAgLULsmkNWnShMOHDxMZGWlYatWqRceOHYmMjMTc3FztEk1KvXr1HngMxalTp/Dz81OpItOWkpKCmZnxnz1zc3OysrJUqkjcLyAgAC8vLyIiIgz7EhMT2b17N3Xq1Mn3z5dbZuKZ9OrViwULFrBixQocHBwM93mdnJywsbFRuTrT4+Dg8ED/LTs7O9zc3KRflwoGDBhA3bp1GTduHG+++SZ79uzhhx9+4IcfflC7NJPUqlUrxo4dS6lSpQgKCuLgwYNMmTKF9957T+3STEZycjJnzpwxbJ8/f57IyEhcXV0pVaoU/fv354svvqBs2bIEBAQwfPhwfHx8DCPR8pUixDMAHrrMnj1b7dJEtoYNGyr9+vVTuwyT9ddffymVK1dWtFqtUqFCBeWHH35QuySTlZiYqPTr108pVaqUYm1trZQuXVoZNmyYkpaWpnZpJmPTpk0P/ZsRHh6uKIqiZGVlKcOHD1c8PT0VrVarNGnSRDl58mSB1CbPIRJCCCGEyZM+REIIIYQweRKIhBBCCGHyJBAJIYQQwuRJIBJCCCGEyZNAJIQQQgiTJ4FICCGEECZPApEQQgghTJ4EIiGEyCWNRsPy5cvVLkMIkQ8kEAkhioTOnTuj0WgeWEJCQtQuTQhRDMhcZkKIIiMkJITZs2cb7dNqtSpVI4QoTqSFSAhRZGi1Wry8vIwWFxcXQH87a8aMGYSGhmJjY0Pp0qX5/fffjd5/+PBhXn75ZWxsbHBzc6N79+4kJycbHfPzzz8TFBSEVqvF29ub3r17G71+8+ZN2rZti62tLWXLluXPP/80vHb79m06duxIiRIlsLGxoWzZsg8EOCFE4SSBSAhRbAwfPpx27doRFRVFx44dad++PcePHwfgzp07NG/eHBcXF/bu3ctvv/3Gxo0bjQLPjBkz6NWrF927d+fw4cP8+eeflClTxugzRo0axZtvvsmhQ4do0aIFHTt25NatW4bPP3bsGGvWrOH48ePMmDEDd3f3gvsCCCGeXoFMISuEEM8oPDxcMTc3V+zs7IyWsWPHKoqiKIDywQcfGL3nhRdeUHr27KkoiqL88MMPiouLi5KcnGx4fdWqVYqZmZkSGxurKIqi+Pj4KMOGDXtkDYDy2WefGbaTk5MVQFmzZo2iKIrSqlUrpUuXLnlzwUKIAiV9iIQQRUbjxo2ZMWOG0T5XV1fDep06dYxeq1OnDpGRkQAcP36cqlWrYmdnZ3i9Xr16ZGVlcfLkSTQaDVeuXKFJkyb/WUOVKlUM63Z2djg6OnL9+nUAevbsSbt27Thw4ADNmjUjLCyMunXrPtW1CiEKlgQiIUSRYWdn98AtrLxiY2OTq+MsLS2NtjUaDVlZWQCEhoYSExPD6tWr2bBhA02aNKFXr15Mnjw5z+sVQuQt6UMkhCg2du3a9cB2xYoVAahYsSJRUVHcuXPH8Pr27dsxMzOjfPnyODg44O/vT0RExDPVUKJECcLDw/n111+ZOnUqP/zwwzOdTwhRMKSFSAhRZKSlpREbG2u0z8LCwtBx+bfffqNWrVq89NJLzJ8/nz179vDTTz8B0LFjRz7//HPCw8MZOXIkN27coE+fPnTq1AlPT08ARo4cyQcffICHhwehoaEkJSWxfft2+vTpk6v6RowYQc2aNQkKCiItLY2VK1caApkQonCTQCSEKDLWrl2Lt7e30b7y5ctz4sQJQD8CbNGiRXz44Yd4e3uzcOFCKlWqBICtrS3r1q2jX79+1K5dG1tbW9q1a8eUKVMM5woPD+fu3bt8/fXXDBo0CHd3d15//fVc12dlZcXQoUOJjo7GxsaG+vXrs2jRojy4ciFEftMoiqKoXYQQQjwrjUbDsmXLCAsLU7sUIUQRJH2IhBBCCGHyJBAJIYQQwuRJHyIhRLEgd/+FEM9CWoiEEEIIYfIkEAkhhBDC5EkgEkIIIYTJk0AkhBBCCJMngUgIIYQQJk8CkRBCCCFMngQiIYQQQpg8CURCCCGEMHkSiIQQQghh8v4P9WsCWHz1SCcAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"code","source":["decoder_input = 'Sara'  # leave as '' or add a prompt (start of story)\n","if decoder_input == '':\n","    decoder_input = sos.unsqueeze(dim=0)\n","else:\n","    decoder_input = torch.cat([sos, torch.tensor(tokenizer.encode(decoder_input))]).unsqueeze(dim=0)\n","\n","while True:\n","    p_all = transformer(torch.tensor(decoder_input))\n","    p_last = p_all[:, -1, :]\n","    p_last = torch.nn.functional.softmax(p_last, dim=1)\n","    p_last = torch.argmax(p_last, dim=1).unsqueeze(dim=0)\n","\n","    decoder_output = torch.cat((decoder_input, p_last), dim=1)\n","\n","    if (decoder_output[0, -1] == 2) or (decoder_output.size(1) == max_seq_length):\n","        break\n","    else:\n","        decoder_input = decoder_output.clone()\n","\n","\n","decoder_output = decoder_output.squeeze().tolist()\n","print(\"Generate:\", tokenizer.decode(decoder_output))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qYD_OI1HglKh","executionInfo":{"status":"ok","timestamp":1712566513663,"user_tz":-60,"elapsed":2198,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"1196169f-27f7-4117-b208-1984b147d7f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-fe51d3ae6b14>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  p_all = transformer(torch.tensor(decoder_input))\n"]},{"output_type":"stream","name":"stdout","text":["Generate: <s> Sara the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and the and and and and and the and the and the and and and the and the and the and the and the and the and the and the and and the and the and the and and and and the and the and and and and and and and and and and the and the and the and the and the and the and the and the and the and the and the and the and the and the dog the and the and the dog the and the and the and the dog the and\n"]}]},{"cell_type":"markdown","source":["Greedy search"],"metadata":{"id":"nap4T-FZ7ym-"}},{"cell_type":"code","source":["def greedy_search(model, img, tokenizer, max_length, index_to_word):\n","    \"\"\"\n","    Greedy Search decoding strategy to generate a caption describing an image\n","\n","    Args:\n","        model: image captioning model\n","        img: image feature vector\n","        tokenizer: tokenizer used for text processing\n","        max_length: maximum length of caption\n","        index_to_word: mapping of word indices to words in vocabulary\n","\n","    Returns:\n","        caption: most likely caption found by Greedy Search\n","    \"\"\"\n","\n","    # Initialize input sequence\n","    caption = 'startseq'\n","\n","    for _ in range(max_length):\n","        # Convert input sequence to integers using the tokenizer\n","        sequence = tokenizer.texts_to_sequences([caption])[0]\n","        # Pad input sequence\n","        padded_sequence = pad_sequences([sequence], maxlen=max_length)\n","        # Predict the next word probabilities\n","        yhat = model.predict([img, padded_sequence], verbose=0)\n","        # Get the index of the word with the highest probability\n","        yhat = np.argmax(yhat)\n","        # Map the index to the word\n","        word = index_to_word[yhat]\n","        # Stop if cannot map the word or if it is an end token\n","        if word is None:\n","            break\n","        elif word == 'endseq':\n","            caption += f' {word}'\n","            break\n","        # Add the predicted word to the input sequence\n","        else:\n","            caption += f' {word}'\n","\n","    return caption\n","\n","\n","def read_image(path, img_size=299):\n","    # Load and resize an image in square format\n","    # and convert it to an array representation\n","    img = load_img(path, target_size=(img_size, img_size))\n","    img = img_to_array(img)/255.\n","\n","    return img\n","\n","\n","def review_captions(decode_strategy, id, index_to_word, encoded_test_images,\n","                    test_captions, model, tokenizer, max_length):\n","\n","    # Plot the Flickr8k image and captions, and the model generated caption\n","    img = encoded_test_images[id].reshape((1, 2048))  # batch size = 1\n","    y_pred = decode_strategy(model, img, tokenizer, max_length, index_to_word)\n","    y_pred = y_pred.replace('startseq ', '')  # Remove start tag\n","    y_pred = y_pred.replace(' endseq', '')  # Remove end tag\n","\n","    print('\\n\\n--- Flickr8k Dataset Captions ---------------------------------')\n","    for caption in test_captions[id]:\n","        caption = caption.replace('startseq ', '')  # Remove start tag\n","        caption = caption.replace(' endseq', '')  # Remove end tag\n","        print(caption)\n","\n","    print('\\n---Caption Predicted by Model----------------------------------')\n","    print(y_pred)\n","\n","    plt.figure(figsize=(3,3))\n","    image = read_image(image_path + id)\n","    plt.imshow(image)\n","    plt.axis('off')\n","    plt.show()\n","\n","\n","def sample_predictions(k, decode_strategy, index_to_word, encoded_test_images,\n","                       test_captions, model, tokenizer, max_length):\n","\n","    random_test_images = random.choices(list(encoded_test_images.keys()), k=k)\n","    for id in tqdm(random_test_images):\n","        review_captions(decode_strategy, id, index_to_word, encoded_test_images,\n","                        test_captions, model, tokenizer, max_length)\n","\n","\n","# Invert the word_index to create a dictionary of index to word\n","index_to_word = {index: word for word, index in word_index.items()}\n","\n","# Demo Greedy Search with random sample of test images and associated captions\n","sample_size = 5\n","sample_predictions(sample_size, greedy_search, index_to_word, encoded_test_images,\n","                   test_captions, model, tokenizer, max_length)\n"],"metadata":{"id":"eQ33Qaox7xHo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def beam_search(model, img, tokenizer, max_length, index_to_word, beam_width=3):\n","    \"\"\"\n","    Beam Search decoding strategy to generate a caption describing an image\n","\n","    Args:\n","        model: image captioning model\n","        img: image feature vector\n","        tokenizer: tokenizer used for text processing\n","        max_length: maximum length of caption\n","        index_to_word: mapping of word indices to words in vocabulary\n","        beam_width: width of the beam\n","            (most probable candidate sequences retained at each step)\n","\n","    Returns:\n","        caption: most likely caption found by Beam Search\n","    \"\"\"\n","\n","    # Initialize input sequence\n","    start_word = [tokenizer.word_index['startseq']]\n","\n","    # Start with single beam\n","    beams = [(0.0, start_word)]  # (log-likelihood, sequence)\n","\n","    while len(beams[0][1]) < max_length:\n","        new_beams = []\n","        for log_prob, sequence in beams:\n","            padded_sequence = pad_sequences([sequence], maxlen=max_length)\n","            yhat = model.predict([img, padded_sequence], verbose=0)\n","            top_words = np.argsort(yhat[0])[-beam_width:]\n","\n","            # Expand each current beam\n","            for word_index in top_words:\n","                new_sequence = sequence + [word_index]\n","                new_log_prob = log_prob + yhat[0][word_index]\n","\n","                new_beams.append((new_log_prob, new_sequence))\n","\n","        # Keep only the top beams\n","        beams = sorted(new_beams, reverse=True)[:beam_width]\n","\n","        # Check if any beam has reached the end sequence\n","        best_sequence = beams[0][1]\n","        if best_sequence[-1] == tokenizer.word_index['endseq']:\n","            break\n","\n","    # Construct the final caption from the best beam\n","    caption = [index_to_word[idx] for idx in best_sequence]\n","    caption = ' '.join(caption)\n","\n","    return caption\n","\n","\n","# Invert the word_index to create a dictionary of index to word\n","index_to_word = {index: word for word, index in word_index.items()}\n","\n","# Demo Beam Search with random sample of test images and associated captions\n","sample_size = 5\n","sample_predictions(sample_size, beam_search, index_to_word, encoded_test_images,\n","                   test_captions, model, tokenizer, max_length)\n"],"metadata":{"id":"4BFoWoSK7-YN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["BLEU SCORES\n","\n","Generate some random stories (use a seed?)\n","and then evaluate them."],"metadata":{"id":"ndouOSy76-kn"}},{"cell_type":"code","source":["# Using test dataset, create lists of actual captions and predicted captions\n","test_actual, test_predicted = [], []\n","\n","for id in tqdm(test_captions):\n","    # get actual caption\n","    captions = test_captions[id]\n","    # predict the caption for image\n","    img = encoded_test_images[id].reshape((1,2048))\n","\n","    # Uncomment preferred decoding strategy\n","    y_pred = beam_search(model, img, tokenizer, max_length, index_to_word, beam_width=7)\n","    #y_pred = greedy_search(model, img, tokenizer, max_length, index_to_word)\n","\n","    # split into words\n","    actual_captions = [caption.split() for caption in captions]\n","    y_pred = y_pred.split()\n","    # append to the list\n","    test_actual.append(actual_captions)\n","    test_predicted.append(y_pred)\n","\n","\n","# Calculate BLEU scores\n","bleu_scores = {}\n","bleu_scores['BLEU-1'] = corpus_bleu(test_actual, test_predicted,\n","                                    weights=(1.0, 0, 0, 0))\n","bleu_scores['BLEU-2'] = corpus_bleu(test_actual, test_predicted,\n","                                    weights=(0.5, 0.5, 0, 0))\n","bleu_scores['BLEU-3'] = corpus_bleu(test_actual, test_predicted,\n","                                    weights=(0.33, 0.33, 0.33, 0))\n","bleu_scores['BLEU-4'] = corpus_bleu(test_actual, test_predicted,\n","                                    weights=(0.25, 0.25, 0.25, 0.25))\n","\n","# Save BLEU scores to pickle\n","model_variation = 'baseline_beam_width7_e8'\n","pickle.dump(bleu_scores,\n","            open(f'{working_directory}bleuscores_{model_variation}.pkl', 'wb'))\n","\n","# Print BLEU scores\n","print(f\"Model Variation: {model_variation}\")\n","print(f\"BLEU-1 Score: {bleu_scores['BLEU-1']}\")\n","print(f\"BLEU-2 Score: {bleu_scores['BLEU-2']}\")\n","print(f\"BLEU-3 Score: {bleu_scores['BLEU-3']}\")\n","print(f\"BLEU-4 Score: {bleu_scores['BLEU-4']}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"BpqMAX_469XG","executionInfo":{"status":"error","timestamp":1712432397903,"user_tz":-60,"elapsed":220,"user":{"displayName":"Mark Hodierne","userId":"10268299263793004126"}},"outputId":"624867f8-ae10-4fef-9633-de06e16124c9"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'test_captions' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-86b6b79153ed>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_actual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_predicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_captions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get actual caption\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcaptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_captions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_captions' is not defined"]}]},{"cell_type":"code","source":["# Load BLEU scores from pickle\n","model_variation = 'baseline_beam_width3_e5'\n","with open(f'{working_directory}bleuscores_{model_variation}.pkl', 'rb') as f:\n","    bleu_scores = pickle.load(f)\n","\n","# Print BLEU scores\n","print(f\"Model Variation: {model_variation}\")\n","print(f\"BLEU-1 Score: {bleu_scores['BLEU-1']}\")\n","print(f\"BLEU-2 Score: {bleu_scores['BLEU-2']}\")\n","print(f\"BLEU-3 Score: {bleu_scores['BLEU-3']}\")\n","print(f\"BLEU-4 Score: {bleu_scores['BLEU-4']}\")\n"],"metadata":{"id":"35YXkjYW7aNZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Bes' code:"],"metadata":{"id":"27cu8VfPE4TV"}},{"cell_type":"code","source":["import random\n","import torch\n","import math\n","\n","\n","torch.manual_seed(42)\n","\n","\n","class Tokenizer:\n","  def __init__(self):\n","    f = open('/root/tiny-transformer/names.txt', 'r')\n","    names = f.read().splitlines()\n","    vocab = ['<pad>', '<eos>', '<sos>'] + sorted(set(''.join(names)))\n","    self.stoi = {c:i for i, c in enumerate(vocab)}\n","    self.itos = {i:c for i, c in enumerate(vocab)}\n","    self.vocab_size = len(vocab)\n","    f.close()\n","\n","  def encode(self, name):\n","    return [self.stoi[c] for c in name]\n","\n","  def decode(self, tokens):\n","    return ''.join([self.itos[t] for t in tokens])\n","\n","\n","tokenizer = Tokenizer()\n","# print(tokenizer.vocab_size)  # 29\n","foo = tokenizer.encode('john') # [2, 12, 17, 10, 16, 1]\n","bar = tokenizer.decode(foo)    # john\n","\n","\n","class Dataset(torch.utils.data.Dataset):\n","  def __init__(self):\n","    f = open('/root/tiny-transformer/names.txt', 'r')\n","    self.names = f.read().split('\\n')\n","    self.tokenizer = Tokenizer()\n","    f.close()\n","\n","  def __len__(self):\n","    return len(self.names)\n","\n","  def __getitem__(self, idx):\n","    name = self.names[idx]\n","    return torch.tensor(self.tokenizer.encode(name))\n","\n","\n","ds = Dataset()\n","dl = torch.utils.data.DataLoader(ds, batch_size=1, shuffle=False)\n","\n","\n","class BesSimpleTransformer(torch.nn.Module):\n","  def __init__(self):\n","    super(BesSimpleTransformer, self).__init__()\n","    # Embedding part of the model\n","    self.embedding    = torch.nn.Embedding(29, 7)\n","    self.pos_emb      = self.get_pos_matrix()\n","    # Mask tensor trick\n","    self.register_buffer('mask', torch.tril(torch.ones(19, 19)))\n","    # First decoder block\n","    self.layer_00_key = torch.nn.Linear(7, 11)\n","    self.layer_00_qry = torch.nn.Linear(7, 11)\n","    self.layer_00_val = torch.nn.Linear(7, 11)\n","    self.layer_00_ffw = torch.nn.Linear(11, 7)\n","    # Second decoder block\n","    self.layer_01_key = torch.nn.Linear(7, 11)\n","    self.layer_01_qry = torch.nn.Linear(7, 11)\n","    self.layer_01_val = torch.nn.Linear(7, 11)\n","    self.layer_01_ffw = torch.nn.Linear(11, 7)\n","    # Output of the model\n","    self.map_to_vocab = torch.nn.Linear(7, 29)\n","\n","  def forward(self, x):\n","    emb = self.embedding(x)\n","    pos = self.pos_emb[0:x.shape[0], :]\n","    emb = emb + pos\n","\n","    key = self.layer_00_key(emb)\n","    qry = self.layer_00_qry(emb)\n","    val = self.layer_00_val(emb)\n","    att = torch.mm(qry, key.t())\n","    msk = self.mask[0:x.shape[0], 0:x.shape[0]]\n","    att = att.masked_fill(msk == 0, float('-inf'))\n","    att = torch.nn.functional.softmax(att, dim=1)\n","    res = torch.mm(att, val)\n","    res = self.layer_00_ffw(res)\n","\n","    key = self.layer_01_key(res)\n","    qry = self.layer_01_qry(res)\n","    val = self.layer_01_val(res)\n","    att = torch.mm(qry, key.t())\n","    msk = self.mask[0:x.shape[0], 0:x.shape[0]]\n","    att = att.masked_fill(msk == 0, float('-inf'))\n","    att = torch.nn.functional.softmax(att, dim=1)\n","    res = torch.mm(att, val)\n","    res = self.layer_01_ffw(res)\n","\n","    out = self.map_to_vocab(res)\n","    return out\n","\n","  def get_pos_matrix(self):\n","    store = torch.zeros(19, 7)\n","    for pos in range(19):\n","      for i in range(0, 7, 2):\n","        denominator = 10000 ** (2 * i / 7)\n","        store[pos, i] = math.sin(pos / denominator)\n","        if i + 1 < 7: store[pos, i + 1] = math.cos(pos / denominator)\n","    return store\n","\n","\n","m = BesSimpleTransformer()\n","opt = torch.optim.SGD(m.parameters(), lr=0.01)\n","\n","\n","for epoch in range(10):\n","  for idx, batch in enumerate(dl):\n","\n","    sos = torch.tensor([2])\n","    eos = torch.tensor([1])\n","\n","    x = batch[0]\n","    x = torch.cat([sos, x])\n","    y = torch.cat([x[1:], eos])\n","\n","    p = m(x)\n","    l = torch.nn.functional.cross_entropy(p, y)\n","    if idx % 1000 == 0: print(\"Loss:\", l.item())\n","    l.backward()\n","    opt.step()\n","    opt.zero_grad()\n","\n","  x = tokenizer.decode([random.randint(3, 25)])\n","  x = torch.cat([sos, torch.tensor(tokenizer.encode([x]))])\n","  while True:\n","    p = m(x)\n","    p = torch.nn.functional.softmax(p, dim=1)\n","    p = torch.argmax(p, dim=1)\n","    x = torch.cat([x, p[-1].unsqueeze(0)])\n","    if p[-1] == 1 or len(p.tolist()) == 17: break\n","  print(\"Generate:\", tokenizer.decode(x.tolist()))\n"],"metadata":{"id":"jsznwzlHWSZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RjNeY1Vmolmf"},"outputs":[],"source":["import torch\n","from torch.nn.utils.rnn import pad_sequence\n","import sentencepiece as spm\n","\n","# Step 1: Tokenization with SentencePiece\n","sp = spm.SentencePieceProcessor()\n","sp.Load(\"path/to/sentencepiece/model.model\")\n","\n","def tokenize_text(text):\n","    return sp.EncodeAsIds(text)\n","\n","# Step 2: Numerical Encoding (already handled by SentencePiece)\n","\n","# Step 3: Padding\n","def pad_sequences(sequences, max_length):\n","    return pad_sequence([torch.tensor(seq) for seq in sequences], batch_first=True, padding_value=0)\n","\n","# Step 4: Create Input and Target Sequences\n","def create_input_target_sequences(texts):\n","    input_sequences = [[sp.bos_id()] + tokenize_text(text) for text in texts]\n","    target_sequences = [tokenize_text(text) + [sp.eos_id()] for text in texts]\n","    return input_sequences, target_sequences\n","\n","# Step 5: Batching\n","def create_batches(input_sequences, target_sequences, batch_size):\n","    batches = []\n","    for i in range(0, len(input_sequences), batch_size):\n","        input_batch = input_sequences[i:i+batch_size]\n","        target_batch = target_sequences[i:i+batch_size]\n","        padded_input = pad_sequences(input_batch, max_length)\n","        padded_target = pad_sequences(target_batch, max_length)\n","        batches.append((padded_input, padded_target))\n","    return batches\n","\n","# Example usage\n","with open(\"your_text_file.txt\", \"r\") as file:\n","    texts = file.readlines()\n","\n","max_length = 128\n","batch_size = 32\n","\n","input_sequences, target_sequences = create_input_target_sequences(texts)\n","batches = create_batches(input_sequences, target_sequences, batch_size)\n","\n","# Now, you can iterate over batches and feed them into your decoder-only transformer model for training.\n"]},{"cell_type":"markdown","source":["To feed tokenized input data into a transformer decoder, you need to prepare the data in the appropriate format and determine the size of the first layer of the decoder based on the size of your token embeddings and the desired model architecture.\n","\n","Here's a general approach you can follow:\n","\n","Tokenize and Pad the Input Data:\n","Tokenize each \"tiny story\" in your input data using the SentencePiece model you trained.\n","Convert the tokenized sequences into token IDs.\n","Pad the sequences to a fixed length (or use padding masks) to ensure consistent input shapes for the transformer decoder.\n","Determine the Embedding Size:\n","The size of the token embeddings is typically a hyperparameter that you need to choose based on your problem and model architecture.\n","Common values for embedding sizes in transformer models range from 128 to 1024, with 512 and 768 being popular choices.\n","Calculate the Size of the First Decoder Layer:\n","The size of the first layer of the transformer decoder depends on the size of the token embeddings and the desired model architecture.\n","In a standard transformer decoder, the first layer is typically a multi-head self-attention layer followed by a feed-forward layer.\n","The input size of the first self-attention layer is equal to the size of the token embeddings.\n","The output size of the first self-attention layer is often set to be the same as the input size (i.e., the embedding size).\n","The feed-forward layer typically has an input size equal to the output size of the self-attention layer and an output size that is a multiple (often 4 times) of the input size.\n","For example, if you choose an embedding size of 512, the size of the first layer of the transformer decoder would be:\n","\n","Input size of the first self-attention layer: 512\n","Output size of the first self-attention layer: 512\n","Input size of the feed-forward layer: 512\n","Output size of the feed-forward layer: 2048 (assuming a multiplier of 4)\n","After the feed-forward layer, the output is typically passed through a layer normalization and residual connection before being fed into the next decoder layer.\n","\n","Here's a simple example of how you can feed the tokenized and padded input data into a transformer decoder in PyTorch:"],"metadata":{"id":"CthsFYCEVFnc"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# Tokenized and padded input data\n","input_ids = ...  # Tensor of shape [batch_size, sequence_length]\n","\n","# Token embeddings\n","embedding_size = 512\n","token_embeddings = nn.Embedding(vocab_size, embedding_size)\n","\n","# First decoder layer\n","self_attn = nn.MultiheadAttention(embed_dim=embedding_size, num_heads=8)\n","feed_forward = nn.Sequential(\n","    nn.Linear(embedding_size, 2048),\n","    nn.ReLU(),\n","    nn.Linear(2048, embedding_size)\n",")\n","\n","# Transformer decoder\n","embedded = token_embeddings(input_ids)\n","attn_output = self_attn(embedded, embedded, embedded)[0]\n","ff_output = feed_forward(attn_output)\n","# ... (Additional decoder layers)"],"metadata":{"id":"l4au9j1VU7bc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In this example, the tokenized input data (input_ids) is first passed through the token embeddings layer (token_embeddings) to obtain the embedded representations. These embeddings are then fed into the first self-attention layer (self_attn), and the output of the self-attention layer is passed through the feed-forward layer (feed_forward).\n","\n","Note that this is a simplified example, and in practice, you would need to handle additional components like positional encodings, layer normalization, residual connections, and possibly other architectural modifications based on your specific transformer decoder implementation."],"metadata":{"id":"T4Dh3ojjU8rM"}}]}